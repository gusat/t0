{
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6729043,
          "sourceType": "datasetVersion",
          "datasetId": 3875963
        }
      ],
      "dockerImageVersionId": 30579,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gusat/t0/blob/master/smd_v1x_3_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Imports and Installations\n",
        "\n",
        "import os\n",
        "import ast\n",
        "import csv\n",
        "import sys\n",
        "import json\n",
        "from pickle import dump\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "import more_itertools as mit\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "# Install Box for dictionaries with attribute access\n",
        "!pip install python-box\n",
        "from box import Box\n",
        "# Clean up the prior installs\n",
        "#!rm -r /kaggle/working/tmp\n",
        "\n",
        "# # NeuroAI install: clone to a directory that won't match the name 'neuroaikit', e.g. tmp\n",
        "# !git clone https://github.com/IBM/neuroaikit.git tmp\n",
        "# !pip install --editable tmp\n",
        "# # Manually add a search path: Python will fail to match 'neuroaikit' and then search under this path and find it:\n",
        "# import sys\n",
        "# sys.path.append('/kaggle/working/tmp')\n",
        "\n",
        "# import neuroaikit as ai\n",
        "# print(dir(ai))\n",
        "\n",
        "# import neuroaikit.tf as aitf\n",
        "# print(dir(aitf))"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.status.busy": "2024-02-23T12:36:07.416871Z",
          "iopub.execute_input": "2024-02-23T12:36:07.417691Z",
          "iopub.status.idle": "2024-02-23T12:36:36.359718Z",
          "shell.execute_reply.started": "2024-02-23T12:36:07.417647Z",
          "shell.execute_reply": "2024-02-23T12:36:36.358527Z"
        },
        "trusted": true,
        "id": "0iVqSOjawZRv",
        "outputId": "12defa8e-c177-43aa-c2ef-873182cf66f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "2.13.0\nCollecting python-box\n  Obtaining dependency information for python-box from https://files.pythonhosted.org/packages/65/63/c2df733c7e9549c1acc6919a3157f8f2fe833fa013052b169e228e1aeb75/python_box-7.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading python_box-7.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\nDownloading python_box-7.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: python-box\nSuccessfully installed python-box-7.1.1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test SNU import\n",
        "# neuron = aitf.layers.SNU(1)\n",
        "# neuron # => <keras.layers.rnn.base_rnn.RNN at 0x7aa438a8a350> is OK"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:36:36.362099Z",
          "iopub.execute_input": "2024-02-23T12:36:36.363151Z",
          "iopub.status.idle": "2024-02-23T12:36:36.368046Z",
          "shell.execute_reply.started": "2024-02-23T12:36:36.363096Z",
          "shell.execute_reply": "2024-02-23T12:36:36.366932Z"
        },
        "trusted": true,
        "id": "PLi1tqi7wZR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Key post-proc. helpers (Telemanom et al. filters) for AE-based AD\n",
        "# Helper classes and functions using the AE reconstruction error as input signal (named Errors, err_... etc.)\n",
        "\n",
        "class Errors:\n",
        "    def __init__(self, error_agg, error, real_data):\n",
        "        \"\"\"\n",
        "        Batch processing of errors between actual and predicted values\n",
        "        for a given error signal.\n",
        "        Args:\n",
        "            error_agg (ndarray): Exponentially-smoothed prediction error\n",
        "            error (ndarray): Errors in prediction (predicted - actual)\n",
        "            real_data (ndarray): Actual data\n",
        "        Attributes:\n",
        "            window_length (int): Number of trailing batches to use in error calculation\n",
        "            nb_windows (int): Number of windows in test values for channel\n",
        "            i_anom (arr): Indices of anomalies in channel test values\n",
        "            E_seq (arr of tuples): Array of (start, end) indices for each continuous anomaly sequence\n",
        "            anom_scores (arr): Score indicating relative severity of each anomaly sequence in E_seq\n",
        "            e (arr): Errors in prediction (predicted - actual)\n",
        "            e_s (arr): Exponentially-smoothed errors in prediction\n",
        "        \"\"\"\n",
        "        self.window_length = 2016\n",
        "        self.nb_windows = 4\n",
        "        self.stride = 144\n",
        "\n",
        "        self.i_anom = np.array([])\n",
        "        self.E_seq = []\n",
        "        self.anom_scores = []\n",
        "\n",
        "        self.e_s = error_agg  # smoothed prediction error\n",
        "        self.e_full = error\n",
        "        self.real_data = real_data\n",
        "\n",
        "\n",
        "    def merge_scores(self):\n",
        "        \"\"\"\n",
        "        If anomalous sequences from subsequent batches are adjacent they\n",
        "        will automatically be combined. This combines the scores for these\n",
        "        initial adjacent sequences (scores are calculated as each batch is\n",
        "        processed) where applicable.\n",
        "        \"\"\"\n",
        "        merged_scores = []\n",
        "        score_end_indices = []\n",
        "\n",
        "        for i, score in enumerate(self.anom_scores):\n",
        "            if not score[\"start_idx\"] - 1 in score_end_indices:\n",
        "                merged_scores.append(score[\"score\"])\n",
        "                score_end_indices.append(score[\"end_idx\"])\n",
        "\n",
        "\n",
        "    def process_batches(self):\n",
        "        \"\"\"\n",
        "        Top-level function for the Error class that loops through batches\n",
        "        of values for a given error signal.\n",
        "        Args:\n",
        "            error (ndarray): 1D error signal\n",
        "        \"\"\"\n",
        "\n",
        "        i = 0\n",
        "        break_flag = False\n",
        "        idx_start = 0\n",
        "        idx_end = idx_start + (self.window_length * self.nb_windows)\n",
        "\n",
        "        while True:\n",
        "\n",
        "            if idx_end > self.e_s.shape[0]:\n",
        "                idx_end = self.e_s.shape[0]\n",
        "                idx_start = idx_end - (self.window_length * self.nb_windows)\n",
        "                break_flag = True\n",
        "            # print(\"-> Evaluating\", self.group_name, \":\", round(idx_end / self.e_s.shape[0] * 100, 2), \"%\", end='\\r')\n",
        "\n",
        "            while True:\n",
        "\n",
        "                # Adapt start idx based on present data gaps and anomaly windows\n",
        "                nb_data_gaps = (\n",
        "                    np.sum(self.real_data[idx_start:idx_end], axis=1) == 0\n",
        "                ).sum()\n",
        "                nb_i_anom = len(\n",
        "                    [x for x in self.i_anom if idx_start <= x and x < idx_end]\n",
        "                )\n",
        "                idx_start = idx_start - (nb_data_gaps + nb_i_anom)\n",
        "                idx_start = max(0, idx_start)\n",
        "\n",
        "                # Compute updated window length\n",
        "                nb_data_gaps = (\n",
        "                    np.sum(self.real_data[idx_start:idx_end], axis=1) == 0\n",
        "                ).sum()\n",
        "                nb_i_anom = len(\n",
        "                    [x for x in self.i_anom if idx_start <= x and x < idx_end]\n",
        "                )\n",
        "                len_cur_window = (idx_end - idx_start) - (nb_data_gaps + nb_i_anom)\n",
        "\n",
        "                # Break if min window length\n",
        "                condition1 = (self.window_length * self.nb_windows) <= len_cur_window\n",
        "                condition2 = idx_start == 0\n",
        "                if condition1 or condition2:\n",
        "                    break\n",
        "\n",
        "            window = ErrorWindow(\n",
        "             idx_start, idx_end, self, i\n",
        "            )\n",
        "            window.find_epsilon()\n",
        "            # window.find_epsilon(inverse=True)\n",
        "            window.compare_to_epsilon()\n",
        "            # window.compare_to_epsilon(inverse=True)\n",
        "\n",
        "            if len(window.i_anom) == 0 and len(window.i_anom_inv) == 0:\n",
        "                if break_flag == True:\n",
        "                    break\n",
        "                i = i + 1\n",
        "                idx_start = i * self.stride\n",
        "                idx_end = idx_start + (self.window_length * self.nb_windows)\n",
        "                continue\n",
        "\n",
        "            window.aw_fp_mitigation()\n",
        "                # window.prune_anoms(inverse=True)\n",
        "\n",
        "            if len(window.i_anom) == 0 and len(window.i_anom_inv) == 0:\n",
        "                if break_flag == True:\n",
        "                    break\n",
        "                i = i + 1\n",
        "                idx_start = i * self.stride\n",
        "                idx_end = idx_start + (self.window_length * self.nb_windows)\n",
        "                continue\n",
        "\n",
        "            window.i_anom = np.sort(\n",
        "                np.unique(np.append(window.i_anom, window.i_anom_inv))\n",
        "            ).astype(\"int\")\n",
        "            window.score_anomalies(idx_start)\n",
        "\n",
        "            # Update indices to reflect true indices in full set of values\n",
        "            self.i_anom = np.sort(\n",
        "                np.unique(np.append(self.i_anom, window.i_anom + idx_start))\n",
        "            )\n",
        "            self.anom_scores = self.anom_scores + window.anom_scores\n",
        "\n",
        "            # Update loop variables\n",
        "            if break_flag:\n",
        "                break\n",
        "\n",
        "            i = i + 1\n",
        "            idx_start = i * self.stride\n",
        "            idx_end = idx_start + (self.window_length * self.nb_windows)\n",
        "\n",
        "        if len(self.i_anom) > 0:\n",
        "            # Group anomalous indices into continuous sequences\n",
        "            groups = [list(group) for group in mit.consecutive_groups(self.i_anom)]\n",
        "            self.E_seq = [(int(g[0]), int(g[-1])) for g in groups if not g[0] == g[-1]]\n",
        "            # aw_vis(self) #TODO: Added for test validation only\n",
        "            self.merge_scores()\n",
        "\n",
        "\n",
        "class ErrorWindow:\n",
        "    def __init__(self, idx_start, idx_end, errors, idx_stride):\n",
        "        \"\"\"\n",
        "        Represents a window for processing errors within a specified index range.\n",
        "        Args:\n",
        "            idx_start (int): Starting index of the window\n",
        "            idx_end (int): Ending index of the window\n",
        "            errors (Errors): Errors class object containing the error signal\n",
        "            idx_stride (int): Index stride for the window\n",
        "        \"\"\"\n",
        "\n",
        "        self.idx_start = idx_start\n",
        "        self.idx_end = idx_end\n",
        "\n",
        "        self.idx_stride = idx_stride\n",
        "\n",
        "        self.prev_i_anom = [\n",
        "            (int(x) - idx_start)\n",
        "            for x in errors.i_anom\n",
        "            if idx_start <= x and x <= idx_end\n",
        "        ]\n",
        "\n",
        "        self.i_anom = np.array([])\n",
        "        self.E_seq = np.array([])\n",
        "        self.non_anom_max = -1000000\n",
        "        self.i_anom_inv = np.array([])\n",
        "        self.E_seq_inv = np.array([])\n",
        "        self.non_anom_max_inv = -1000000\n",
        "\n",
        "        # TODO: self.error_buffer = self.config.as_threshold.rolling_window_length_mean\n",
        "        self.error_buffer = 6\n",
        "        self.magnitude_similarity_threshold = (\n",
        "            0.2\n",
        "        )\n",
        "        self.duration_similarity_threshold = (\n",
        "            0.2\n",
        "        )\n",
        "        self.sd_lim_low = 0\n",
        "        self.sd_lim = 12\n",
        "\n",
        "        self.sd_threshold = self.sd_lim\n",
        "        self.sd_threshold_inv = self.sd_lim\n",
        "\n",
        "        self.anom_scores = []\n",
        "        self.e_s = errors.e_s[idx_start:idx_end].copy()\n",
        "        self.e_full = errors.e_full[idx_start:idx_end].copy()\n",
        "        self.real_data = errors.real_data[idx_start:idx_end].copy()\n",
        "\n",
        "        self.mean_e_s = np.mean(self.e_s)\n",
        "        self.sd_e_s = np.std(self.e_s)\n",
        "        self.e_s_inv = np.array([self.mean_e_s + (self.mean_e_s - e) for e in self.e_s])\n",
        "\n",
        "        self.epsilon = self.mean_e_s + self.sd_lim * self.sd_e_s\n",
        "        self.epsilon_inv = self.mean_e_s + self.sd_lim * self.sd_e_s\n",
        "\n",
        "        self.values = (\n",
        "            errors.real_data[idx_start:idx_end]\n",
        "            if len(errors.real_data.shape) == 1\n",
        "            else (np.sum(errors.real_data[idx_start:idx_end], axis=1))\n",
        "        )\n",
        "        self.sd_values = np.std(self.values)\n",
        "\n",
        "        self.perc_high, self.perc_low = np.percentile(self.values, [95, 5])\n",
        "        self.inter_range = self.perc_high - self.perc_low\n",
        "\n",
        "\n",
        "    def find_epsilon(self, inverse=False):\n",
        "        \"\"\"\n",
        "        Find the anomaly threshold that maximizes function representing\n",
        "        tradeoff between:\n",
        "            a) number of anomalies and anomalous ranges\n",
        "            b) the reduction in mean and st dev if anomalous points are removed\n",
        "            from errors\n",
        "        (see https://arxiv.org/pdf/1802.04431.pdf)\n",
        "        Args:\n",
        "            inverse (bool): If true, epsilon is calculated for inverted errors\n",
        "        \"\"\"\n",
        "        # Mask error where data gaps appear or known anomalies exist\n",
        "        mask_data_gap = np.sum(self.real_data, axis=1) == 0\n",
        "        mask_i_anom = np.zeros(self.e_s.shape, dtype=bool)\n",
        "        mask_i_anom[self.prev_i_anom] = True\n",
        "        mask_threshold = mask_data_gap | mask_i_anom\n",
        "\n",
        "        e_s = np.ma.masked_array(\n",
        "            self.e_s if not inverse else self.e_s_inv, mask=mask_threshold\n",
        "        )\n",
        "        mean_e_s = e_s.mean()\n",
        "        sd_e_s = e_s.std()\n",
        "\n",
        "        max_score = -10000000\n",
        "\n",
        "        list_epsilons = []\n",
        "        for z in np.arange(self.sd_lim_low, self.sd_lim, 0.5):\n",
        "            epsilon = mean_e_s + (sd_e_s * z)\n",
        "            pruned_e_s = e_s[e_s < epsilon]\n",
        "\n",
        "            i_anom = np.argwhere(e_s >= epsilon).reshape(\n",
        "                -1,\n",
        "            )\n",
        "            buffer = np.arange(1, self.error_buffer)\n",
        "            i_anom = np.sort(\n",
        "                np.concatenate(\n",
        "                    (\n",
        "                        i_anom,\n",
        "                        np.array([i + buffer for i in i_anom]).flatten(),\n",
        "                        np.array([i - buffer for i in i_anom]).flatten(),\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "            i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
        "            i_anom = np.sort(np.unique(i_anom))\n",
        "\n",
        "            if len(i_anom) > 0:\n",
        "                # Group anomalous indices into continuous sequences\n",
        "                groups = [list(group) for group in mit.consecutive_groups(i_anom)]\n",
        "                E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
        "\n",
        "                mean_perc_decrease = (mean_e_s - pruned_e_s.mean()) / mean_e_s\n",
        "                sd_perc_decrease = (sd_e_s - pruned_e_s.std()) / sd_e_s\n",
        "                score = (mean_perc_decrease + sd_perc_decrease) / (\n",
        "                    len(E_seq) ** 2 + len(i_anom)\n",
        "                )  # original\n",
        "\n",
        "                list_epsilons.append((z, score))\n",
        "\n",
        "                # Sanity checks / guardrails to update threshold level\n",
        "                # - current threshold level must produce less then 5 anomaly sequences\n",
        "                # - current threshold level must threhold less then 50% of data points as anomalous\n",
        "\n",
        "                if (\n",
        "                    score >= max_score\n",
        "                    and len(E_seq) <= 5  # TODO take away\n",
        "                    and len(i_anom) < (len(e_s) * 0.5)\n",
        "                ):\n",
        "                    max_score = score\n",
        "                    if not inverse:\n",
        "                        self.sd_threshold = z\n",
        "                        self.epsilon = mean_e_s + z * sd_e_s\n",
        "                    else:\n",
        "                        self.sd_threshold_inv = z\n",
        "                        self.epsilon_inv = mean_e_s + z * sd_e_s\n",
        "\n",
        "        # Plot epsilon score for current window\n",
        "        # plot_telemanom_epsilon(\n",
        "        #     config=self.config,aw\n",
        "        #     group_name=self.group_name,\n",
        "        #     idx_start=self.idx_start,\n",
        "        #     idx_end=self.idx_end,\n",
        "        #     signal=e_s,\n",
        "        #     epsilon=self.epsilon,\n",
        "        #     epsilon_scores=list_epsilons)\n",
        "\n",
        "\n",
        "    def compare_to_epsilon(self, inverse=False):\n",
        "        \"\"\"\n",
        "        Compare smoothed error values to epsilon (error threshold) and group\n",
        "        consecutive errors together into sequences.\n",
        "        Args:\n",
        "            inverse (bool): If true, epsilon is calculated for inverted errors\n",
        "            errors_all (obj): Errors class object containing list of all\n",
        "            previously identified anomalies in test set\n",
        "        \"\"\"\n",
        "        e_s = self.e_s if not inverse else self.e_s_inv\n",
        "        epsilon = self.epsilon if not inverse else self.epsilon_inv\n",
        "\n",
        "        # also take the below away: TODO\n",
        "        if (\n",
        "            not (\n",
        "                self.sd_e_s > (0.05 * self.sd_values)\n",
        "                or max(self.e_s) > (0.05 * self.inter_range)\n",
        "            )\n",
        "            or not max(self.e_s) > 0.05\n",
        "        ):\n",
        "            return\n",
        "\n",
        "        i_anom = np.argwhere(\n",
        "            (e_s >= epsilon) & (e_s > 0.05 * self.inter_range)\n",
        "        ).reshape(\n",
        "            -1,\n",
        "        )\n",
        "\n",
        "        if len(i_anom) == 0:\n",
        "            return\n",
        "\n",
        "        buffer = np.arange(1, self.error_buffer + 1)\n",
        "\n",
        "        i_anom = np.sort(\n",
        "            np.concatenate(\n",
        "                (\n",
        "                    i_anom,\n",
        "                    np.array([i + buffer for i in i_anom]).flatten(),\n",
        "                    np.array([i - buffer for i in i_anom]).flatten(),\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
        "        i_anom = np.sort(np.unique(i_anom))\n",
        "\n",
        "        # Capture max of non-anomalous values below the threshold\n",
        "        # (used in filtering process)\n",
        "        window_indices = np.arange(0, len(e_s))\n",
        "        candidate_indices = np.setdiff1d(window_indices, i_anom)\n",
        "        non_anom_max = np.max(np.take(e_s, candidate_indices))\n",
        "\n",
        "        # Group anomalous indices into continuous sequences\n",
        "        groups = [list(group) for group in mit.consecutive_groups(i_anom)]\n",
        "        E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
        "\n",
        "        if inverse:\n",
        "            self.i_anom_inv = i_anom\n",
        "            self.E_seq_inv = E_seq\n",
        "            self.non_anom_max_inv = non_anom_max\n",
        "        else:\n",
        "            self.i_anom = i_anom\n",
        "            self.E_seq = E_seq\n",
        "            self.non_anom_max = non_anom_max\n",
        "\n",
        "\n",
        "    def score_anomalies(self, idx_start):\n",
        "        \"\"\"\n",
        "        Calculate anomaly scores based on max distance from epsilon\n",
        "        for each anomalous sequence.\n",
        "        Args:\n",
        "            prior_idx (int): starting index of window within full set of test\n",
        "                values for channel\n",
        "        \"\"\"\n",
        "\n",
        "        groups = [list(group) for group in mit.consecutive_groups(self.i_anom)]\n",
        "\n",
        "        for e_seq in groups:\n",
        "\n",
        "            score_dict = {\n",
        "                \"start_idx\": e_seq[0] + idx_start,\n",
        "                \"end_idx\": e_seq[-1] + idx_start,\n",
        "                \"score\": 0,\n",
        "            }\n",
        "\n",
        "            score = max(\n",
        "                [\n",
        "                    abs(self.e_s[i] - self.epsilon) / (self.mean_e_s + self.sd_e_s)\n",
        "                    for i in range(e_seq[0], e_seq[-1] + 1)\n",
        "                ]\n",
        "            )\n",
        "            inv_score = max(\n",
        "                [\n",
        "                    abs(self.e_s_inv[i] - self.epsilon_inv)\n",
        "                    / (self.mean_e_s + self.sd_e_s)\n",
        "                    for i in range(e_seq[0], e_seq[-1] + 1)\n",
        "                ]\n",
        "            )\n",
        "            # The max score indicates whether anomaly was from regular\n",
        "            # or inverted errors\n",
        "            score_dict[\"score\"] = max([score, inv_score])\n",
        "            self.anom_scores.append(score_dict)\n",
        "\n",
        "\n",
        "    def aw_fp_mitigation(self, inverse=False):\n",
        "        \"\"\"\n",
        "        Remove anomalies that don't meet minimum separation from the next\n",
        "        closest anomaly or error value\n",
        "        Args:\n",
        "            inverse (bool): If true, epsilon is calculated for inverted errors\n",
        "        \"\"\"\n",
        "        E_seq = self.E_seq if not inverse else self.E_seq_inv\n",
        "        e_s = self.e_s if not inverse else self.e_s_inv\n",
        "        non_anom_max = self.non_anom_max if not inverse else self.non_anom_max_inv\n",
        "\n",
        "        if len(E_seq) == 0:\n",
        "            return\n",
        "\n",
        "        # (1) Self-similarity space: Novelty pruning based on similar magnitude. Remove anomalies of similar magnitude.\n",
        "        # Assumption: Anomalies of same magnitued are not frequently recurring within the same channel\n",
        "        E_seq_max = np.array([max(e_s[e[0]:e[-1]+1]) for e in E_seq])\n",
        "        E_seq_max_sorted = np.sort(E_seq_max)[::-1]\n",
        "        E_seq_max_sorted = np.append(E_seq_max_sorted, [non_anom_max])\n",
        "\n",
        "        i_to_remove = np.array([], dtype=int)\n",
        "        for i in range(0, len(E_seq_max_sorted)-1):\n",
        "            cur_similarity = abs(E_seq_max_sorted[i] - E_seq_max_sorted[i+1]) / (E_seq_max_sorted[i] + E_seq_max_sorted[i+1])\n",
        "            # print(f\"-> AW {i} | Severity similarity: {cur_similarity}\")\n",
        "            if cur_similarity < self.magnitude_similarity_threshold:\n",
        "                i_to_remove = np.append(i_to_remove, np.argwhere(E_seq_max == E_seq_max_sorted[i]))\n",
        "                i_to_remove = np.append(i_to_remove, np.argwhere(E_seq_max == E_seq_max_sorted[i+1]))\n",
        "                # print(\"-> Change of magnitude low:\", round(abs(E_seq_max_sorted[i] - E_seq_max_sorted[i+1]) / E_seq_max_sorted[i], 2))\n",
        "\n",
        "        i_to_remove = np.unique(i_to_remove)\n",
        "        i_to_remove.sort()\n",
        "\n",
        "        # print(\"-> Number of 1st stage removal candidates\", len(i_to_remove))\n",
        "\n",
        "        # (2) Self-similarity time: Pruning of candidates based on similar duration. Remove anomalies of similar magnitude and duration.\n",
        "        # Assumption: Anomalies of same magnitude and duration are not frequently recurring within the same\n",
        "        if len(i_to_remove) > 1:\n",
        "\n",
        "            E_seq_lengths = np.array([ e[1]-e[0] for e in np.asarray(E_seq)[i_to_remove] ])\n",
        "            E_seq_lengths_sorted = np.sort(np.unique(E_seq_lengths))[::-1]\n",
        "\n",
        "            if not len(E_seq_lengths_sorted) == 1:\n",
        "                E_seq_lengths_sorted = np.append(E_seq_lengths_sorted, [E_seq_lengths_sorted[-2]])\n",
        "                i_to_remove_2nd = np.array([], dtype=int)\n",
        "\n",
        "                for i in range(0, len(E_seq_lengths_sorted)-1):\n",
        "                    if ((abs(E_seq_lengths_sorted[i] - E_seq_lengths_sorted[i+1]) / (E_seq_lengths_sorted[i] + E_seq_lengths_sorted[i+1])) < self.duration_similarity_threshold):\n",
        "                        i_to_remove_2nd = np.append(i_to_remove_2nd, np.argwhere(E_seq_lengths == E_seq_lengths_sorted[i]))\n",
        "                        i_to_remove_2nd = np.append(i_to_remove_2nd, np.argwhere(E_seq_lengths == E_seq_lengths_sorted[i+1]))\n",
        "                        # print(\"-> Change of duration low:\", round(abs(E_seq_lengths_sorted[i] - E_seq_lengths_sorted[i+1]) / E_seq_lengths_sorted[i], 2))\n",
        "\n",
        "                i_to_remove_2nd = np.unique(i_to_remove_2nd)\n",
        "                i_to_remove_2nd.sort()\n",
        "\n",
        "                # print(\"-> Number of 2st stage removal candidates\", len(i_to_remove_2nd))\n",
        "\n",
        "                if len(i_to_remove_2nd) > 0:\n",
        "                    i_to_remove = i_to_remove[i_to_remove_2nd]\n",
        "                else:\n",
        "                    i_to_remove = np.array([], dtype=int)\n",
        "        if len(i_to_remove) > 0:\n",
        "            # print(\"-> Removing\", len(i_to_remove), \"novelties due to similar magnitude /and duration\")\n",
        "            E_seq = np.delete(E_seq, i_to_remove, axis=0)\n",
        "\n",
        "        if len(E_seq) == 0 and inverse:\n",
        "            self.i_anom_inv = np.array([])\n",
        "            return\n",
        "        if len(E_seq) == 0 and not inverse:\n",
        "            self.i_anom = np.array([])\n",
        "            return\n",
        "\n",
        "        indices_to_keep = np.concatenate([range(e_seq[0], e_seq[-1]+1) for e_seq in E_seq])\n",
        "\n",
        "        if not inverse:\n",
        "            mask = np.isin(self.i_anom, indices_to_keep)\n",
        "            # Count true values before vs after\n",
        "            self.i_anom = self.i_anom[mask]\n",
        "            self.E_seq = E_seq\n",
        "\n",
        "        else:\n",
        "            mask_inv = np.isin(self.i_anom_inv, indices_to_keep)\n",
        "            self.i_anom_inv = self.i_anom_inv[mask_inv]\n",
        "            self.E_seq_inv = E_seq\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:36:36.369649Z",
          "iopub.execute_input": "2024-02-23T12:36:36.369940Z",
          "iopub.status.idle": "2024-02-23T12:36:36.438329Z",
          "shell.execute_reply.started": "2024-02-23T12:36:36.369915Z",
          "shell.execute_reply": "2024-02-23T12:36:36.437436Z"
        },
        "trusted": true,
        "id": "AsPA1mduwZR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_nlp.layers import TransformerEncoder, TransformerDecoder, SinePositionEncoding\n",
        "#import aitf  # Import the NeuroAI toolkit\n",
        "\n",
        "# Part 3a: Define the 4 core AE models for AD: SNU- / LSTM- / 2x Transformer-based Autoencoders\n",
        "\n",
        "# Define LSTM Model\n",
        "def build_lstm_model():\n",
        "    \"\"\"Instantiates the lstm / AE architecture.\"\"\"\n",
        "    # Initialize early stopping callback and optimizer\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=5, verbose=1, restore_best_weights=True\n",
        "    )\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.1,\n",
        "        clipnorm=1,\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(config.window_length, config.num_features)))\n",
        "    model.add(\n",
        "        layers.LSTM(\n",
        "            128,\n",
        "            return_sequences=True,\n",
        "            input_shape=(config.window_length, config.num_features),\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(rate=0.2))\n",
        "    model.add(layers.LSTM(7, return_sequences=True))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(rate=0.2))\n",
        "    model.add(layers.LSTM(config.num_features, return_sequences=True))\n",
        "    model.summary()\n",
        "\n",
        "    # Build and compile model\n",
        "    print(\"Compiling model...\")\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "        metrics=[\"mse\", \"mae\"],\n",
        "    )\n",
        "\n",
        "    return model, early_stop\n",
        "\n",
        "# Define Transformer Model\n",
        "def build_transformer_model():\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=5, verbose=10, restore_best_weights=True\n",
        "    )\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.0005,\n",
        "        clipnorm=1,\n",
        "    )\n",
        "    # add a time encoding:\n",
        "\n",
        "    inputs = keras.Input(shape=(config.window_length, config.num_features))\n",
        "\n",
        "    x = inputs\n",
        "    positional_encoding = SinePositionEncoding()(x)\n",
        "    x = x + positional_encoding\n",
        "    for idx in range(2):\n",
        "        x = TransformerEncoder(\n",
        "            intermediate_dim=128,\n",
        "            num_heads=5,\n",
        "            dropout=0.1,\n",
        "        )(x)\n",
        "        x = layers.Dense([20,7][idx],\n",
        "                         activation='relu')(x)\n",
        "\n",
        "    # x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    # decoder: (usinfg encoder here actually as we do not want masking)\n",
        "    for idx, _ in enumerate(\n",
        "        range(2)\n",
        "    ):\n",
        "        x = TransformerEncoder(\n",
        "            intermediate_dim=128,\n",
        "            num_heads=5,\n",
        "            dropout=0.1,\n",
        "        )(x)\n",
        "        x = layers.Dense(\n",
        "            [20, 32][idx],\n",
        "            activation=\"relu\",\n",
        "        )(x)\n",
        "\n",
        "    # for dim in config.AD_model.TransformerAE.mlp_units:\n",
        "    # x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "    # x = layers.Dropout(config.AD_model.TransformerAE.mlp_dropout)(x)\n",
        "\n",
        "    # decoder between the last two\n",
        "\n",
        "    outputs = layers.Dense(38, activation='relu')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.summary()\n",
        "\n",
        "    print(\"Compiling model...\")\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "        metrics=[\"mse\", \"mae\"],\n",
        "    )\n",
        "    return model, early_stop\n",
        "\n",
        "\n",
        "# Part 3b: SNU-based LSTM and transformer AE models\n",
        "\n",
        "# Define the configuration for the SNU layers\n",
        "config = {'activation': tf.nn.sigmoid, 'recurrent': True, 'decay': 0.98, 'g': tf.identity}\n",
        "# config = {'activation': tf.nn.leaky_relu, 'recurrent': True, 'decay': 0.98, 'g': tf.identity} # NaN in fit\n",
        "input_shape = (120, 38) # used hard-coded for SNU models\n",
        "\n",
        "def build_snu_model():\n",
        "    \"\"\"Instantiates the SNU-based / LSTM-like AE architecture.\"\"\"\n",
        "    # Initialize early stopping callback and optimizer\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=5, verbose=1, restore_best_weights=True\n",
        "    )\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.001,\n",
        "        clipnorm=0.5,\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=input_shape))\n",
        "    model.add(\n",
        "        aitf.layers.SNU(\n",
        "            128,\n",
        "            **config,\n",
        "            return_sequences=True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(rate=0.2))\n",
        "    model.add(aitf.layers.SNU(7, **config, return_sequences=True))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(rate=0.2))\n",
        "    model.add(aitf.layers.SNU(38, **config, return_sequences=True))\n",
        "    model.summary()\n",
        "\n",
        "    # Build and compile model\n",
        "    print(\"Compiling model...\")\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "        metrics=[\"mse\", \"mae\"],\n",
        "    )\n",
        "\n",
        "    return model, early_stop\n",
        "\n",
        "\n",
        "# B) Simple SNU-based transformer AE\n",
        "def build_snu_transformer_AE():\n",
        "    \"\"\"Instantiates the SNU / Transformer AE architecture.\n",
        "    # Arguments\n",
        "        config: configuration file containing hyperparameters to build AE\n",
        "    # Returns\n",
        "        A Keras model instance 88k (vs. 34k native) parms\n",
        "    \"\"\"\n",
        "    # Initialize early stopping callback and optimizer\n",
        "    early_stopping = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=5, verbose=10, restore_best_weights=True\n",
        "    )\n",
        "    optimizer = Adam(\n",
        "        learning_rate=0.0005,\n",
        "        clipnorm=1,\n",
        "    )\n",
        "\n",
        "    # Define the configuration for the SNU layers\n",
        "    config_snu = {'activation': tf.nn.sigmoid, 'recurrent': True, 'decay': 0.995, 'g':  tf.identity}\n",
        "\n",
        "    # Create model\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    positional_encoding = SinePositionEncoding()(x)\n",
        "    x = x + positional_encoding\n",
        "    # positional_encoding = aitf.layers.SinePositionEncoding()(x) => functionally equiv., more explicit and flexible method to add layer\n",
        "    # x = layers.Add()([x, positional_encoding])\n",
        "\n",
        "    for idx in range(2):\n",
        "        x = aitf.layers.SNU(\n",
        "            128,\n",
        "            **config_snu,\n",
        "            return_sequences=True\n",
        "        )(x)\n",
        "        x = layers.Dense([20,7][idx], activation='relu')(x)\n",
        "\n",
        "    # Decoder\n",
        "    for idx, _ in enumerate(range(2)):\n",
        "        x = aitf.layers.SNU(\n",
        "            128,\n",
        "            **config_snu,\n",
        "            return_sequences=True\n",
        "        )(x)\n",
        "        x = layers.Dense([20, 32][idx], activation=\"relu\")(x)\n",
        "\n",
        "    outputs = layers.Dense(38, activation='relu')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.summary()\n",
        "\n",
        "    # Build and compile model\n",
        "    print(\"Compiling model...\")\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "        metrics=[\"mse\", \"mae\"],\n",
        "    )\n",
        "\n",
        "    return model, early_stopping\n",
        "\n",
        "# Example usage SNU models:\n",
        "# input_shape = (sequence_length, features)  # Replace with our actual input shape (120,38)\n",
        "# model, early_stopping = build_snu_transformer_AE(input_shape)\n",
        "\n",
        "# Build an AE model of the 4 possible autoencoders (2x plain + 2 SNU-based versions)\n",
        "# model, early_stop = build_snu_transformer_AE()\n",
        "# model1, early_stop1 = build_snu_model()  # => LSTM-like SNU-based AE\n",
        "# model2, early_stop2 = build_lstm_model()\n",
        "# model3, early_stop3 = build_transformer_model()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:36:36.440467Z",
          "iopub.execute_input": "2024-02-23T12:36:36.440791Z",
          "iopub.status.idle": "2024-02-23T12:36:38.114109Z",
          "shell.execute_reply.started": "2024-02-23T12:36:36.440766Z",
          "shell.execute_reply": "2024-02-23T12:36:38.113338Z"
        },
        "trusted": true,
        "id": "qIYdfvXTwZR8",
        "outputId": "39275969-6ce5-4bf9-ef3f-0964d2de5f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Using TensorFlow backend\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4a: SMD Corpus FE / Dataset cooking...\n",
        "# Dataset Preparation and Ingestion\n",
        "#=================================================================\n",
        "# Prepare the SMD dataset for ingestion\n",
        "# IN folder from the default SMD dataset created in kaggle\n",
        "dataset_path = '/kaggle/input'\n",
        "print(\"kaggle SMD dataset input from = \", dataset_path)\n",
        "\n",
        "# OUT folder for pre-processing the SMD raw dataset\n",
        "output = '/kaggle/working'\n",
        "output_folder = os.path.join(output, 'ServerMachineDataset', 'processed')\n",
        "print(\"output_folder = \", output_folder)\n",
        "\n",
        "# %%\n",
        "# IO helper functions\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "def load_and_save(category, filename, dataset, dataset_folder):\n",
        "    temp = np.genfromtxt(os.path.join(dataset_path,dataset_folder, category, filename),\n",
        "                         dtype=np.float32,\n",
        "                         delimiter=',')\n",
        "    print(dataset, category, filename, temp.shape)\n",
        "    with open(os.path.join(output_folder, dataset + \"_\" + category + \".pkl\"), \"wb\") as file:\n",
        "        dump(temp, file)\n",
        "\n",
        "def load_data(dataset):\n",
        "    if dataset == 'SMD':\n",
        "        dataset_folder = 'smd-onmiad/ServerMachineDataset'\n",
        "        file_list = os.listdir(os.path.join(dataset_path, dataset_folder, \"train\"))\n",
        "        for filename in file_list:\n",
        "            if filename.endswith('.txt'):\n",
        "                load_and_save('train', filename, filename.strip('.txt'), dataset_folder)\n",
        "                load_and_save('test', filename, filename.strip('.txt'), dataset_folder)\n",
        "                load_and_save('test_label', filename, filename.strip('.txt'), dataset_folder)\n",
        "\n",
        "def list_folder(folder):\n",
        "    for dirname, _, filenames in os.walk(folder):\n",
        "        for filename in filenames:\n",
        "            print(os.path.join(dirname, filename))\n",
        "\n",
        "\n",
        "# %%\n",
        "# Prepare the SMD dataset: Contains train and test data from 28 SMD servers, each 38 KPIs (anon, i.e., names are masked), for 5 weeks, Tsampling ~ 2min\n",
        "# add here\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def get_data(dataset, max_train_size=None, max_test_size=None, print_log=True, do_preprocess=True, train_start=0,\n",
        "             test_start=0):\n",
        "    \"\"\"\n",
        "    get data from pkl files\n",
        "    return shape: (([train_size, x_dim], [train_size] or None), ([test_size, x_dim], [test_size]))\n",
        "    \"\"\"\n",
        "    if max_train_size is None:\n",
        "        train_end = None\n",
        "    else:\n",
        "        train_end = train_start + max_train_size\n",
        "    if max_test_size is None:\n",
        "        test_end = None\n",
        "    else:\n",
        "        test_end = test_start + max_test_size\n",
        "    print('load data of:', dataset)\n",
        "    print(\"train: \", train_start, train_end)\n",
        "    print(\"test: \", test_start, test_end)\n",
        "    x_dim = 38\n",
        "    f = open(os.path.join(output_folder, dataset + '_train.pkl'), \"rb\")\n",
        "    train_data = pickle.load(f).reshape((-1, x_dim))[train_start:train_end, :]\n",
        "    f.close()\n",
        "    try:\n",
        "        f = open(os.path.join(output_folder, dataset + '_test.pkl'), \"rb\")\n",
        "        test_data = pickle.load(f).reshape((-1, x_dim))[test_start:test_end, :]\n",
        "        f.close()\n",
        "    except (KeyError, FileNotFoundError):\n",
        "        test_data = None\n",
        "    try:\n",
        "        f = open(os.path.join(output_folder, dataset + \"_test_label.pkl\"), \"rb\")\n",
        "        test_label = pickle.load(f).reshape((-1))[test_start:test_end]\n",
        "        f.close()\n",
        "    except (KeyError, FileNotFoundError):\n",
        "        test_label = None\n",
        "    if do_preprocess:\n",
        "        train_data = preprocess(train_data)\n",
        "        test_data = preprocess(test_data)\n",
        "    print(\"train set shape: \", train_data.shape)\n",
        "    print(\"test set shape: \", test_data.shape)\n",
        "    print(\"test set label shape: \", test_label.shape)\n",
        "    return (train_data, None), (test_data, test_label)\n",
        "\n",
        "\n",
        "def preprocess(df):\n",
        "    \"\"\"returns normalized and standardized data.\n",
        "    \"\"\"\n",
        "\n",
        "    df = np.asarray(df, dtype=np.float32)\n",
        "\n",
        "    if len(df.shape) == 1:\n",
        "        raise ValueError('Data must be a 2-D array')\n",
        "\n",
        "    if np.any(sum(np.isnan(df)) != 0):\n",
        "        print('Data contains NaN values. Will be replaced with 0')\n",
        "        df = np.nan_to_num()\n",
        "\n",
        "#     # normalize data -> SMD data is natively normalized already [0,1]\n",
        "#     df = MinMaxScaler().fit_transform(df)\n",
        "#     print('Data normalized')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:36:38.115286Z",
          "iopub.execute_input": "2024-02-23T12:36:38.115588Z",
          "iopub.status.idle": "2024-02-23T12:36:38.135402Z",
          "shell.execute_reply.started": "2024-02-23T12:36:38.115563Z",
          "shell.execute_reply": "2024-02-23T12:36:38.134556Z"
        },
        "trusted": true,
        "id": "r13HGcPHwZR-",
        "outputId": "da5417f3-0797-4c9d-ec65-a2d0ce7e1397"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "kaggle SMD dataset input from =  /kaggle/input\noutput_folder =  /kaggle/working/ServerMachineDataset/processed\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SMD\n",
        "load_data('SMD')\n",
        "#list_folder('/kaggle/working')\n",
        "print(\"Done loading and pre-processing SMD into pkl files.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:36:38.136478Z",
          "iopub.execute_input": "2024-02-23T12:36:38.136738Z",
          "iopub.status.idle": "2024-02-23T12:37:27.941980Z",
          "shell.execute_reply.started": "2024-02-23T12:36:38.136715Z",
          "shell.execute_reply": "2024-02-23T12:37:27.940933Z"
        },
        "trusted": true,
        "id": "o3OYVP-0wZR_",
        "outputId": "7a52647b-11d3-4a73-aafb-2e5b5a42ff9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "machine-3-1 train machine-3-1.txt (28700, 38)\nmachine-3-1 test machine-3-1.txt (28700, 38)\nmachine-3-1 test_label machine-3-1.txt (28700,)\nmachine-1-1 train machine-1-1.txt (28479, 38)\nmachine-1-1 test machine-1-1.txt (28479, 38)\nmachine-1-1 test_label machine-1-1.txt (28479,)\nmachine-3-5 train machine-3-5.txt (23690, 38)\nmachine-3-5 test machine-3-5.txt (23691, 38)\nmachine-3-5 test_label machine-3-5.txt (23691,)\nmachine-1-5 train machine-1-5.txt (23705, 38)\nmachine-1-5 test machine-1-5.txt (23706, 38)\nmachine-1-5 test_label machine-1-5.txt (23706,)\nmachine-2-9 train machine-2-9.txt (28722, 38)\nmachine-2-9 test machine-2-9.txt (28722, 38)\nmachine-2-9 test_label machine-2-9.txt (28722,)\nmachine-2-8 train machine-2-8.txt (23702, 38)\nmachine-2-8 test machine-2-8.txt (23703, 38)\nmachine-2-8 test_label machine-2-8.txt (23703,)\nmachine-3-11 train machine-3-11.txt (28695, 38)\nmachine-3-11 test machine-3-11.txt (28696, 38)\nmachine-3-11 test_label machine-3-11.txt (28696,)\nmachine-3-7 train machine-3-7.txt (28705, 38)\nmachine-3-7 test machine-3-7.txt (28705, 38)\nmachine-3-7 test_label machine-3-7.txt (28705,)\nmachine-2-1 train machine-2-1.txt (23693, 38)\nmachine-2-1 test machine-2-1.txt (23694, 38)\nmachine-2-1 test_label machine-2-1.txt (23694,)\nmachine-1-6 train machine-1-6.txt (23688, 38)\nmachine-1-6 test machine-1-6.txt (23689, 38)\nmachine-1-6 test_label machine-1-6.txt (23689,)\nmachine-3-9 train machine-3-9.txt (28713, 38)\nmachine-3-9 test machine-3-9.txt (28713, 38)\nmachine-3-9 test_label machine-3-9.txt (28713,)\nmachine-3-6 train machine-3-6.txt (28726, 38)\nmachine-3-6 test machine-3-6.txt (28726, 38)\nmachine-3-6 test_label machine-3-6.txt (28726,)\nmachine-3-10 train machine-3-10.txt (23692, 38)\nmachine-3-10 test machine-3-10.txt (23693, 38)\nmachine-3-10 test_label machine-3-10.txt (23693,)\nmachine-2-3 train machine-2-3.txt (23688, 38)\nmachine-2-3 test machine-2-3.txt (23689, 38)\nmachine-2-3 test_label machine-2-3.txt (23689,)\nmachine-2-7 train machine-2-7.txt (23696, 38)\nmachine-2-7 test machine-2-7.txt (23696, 38)\nmachine-2-7 test_label machine-2-7.txt (23696,)\nmachine-2-2 train machine-2-2.txt (23699, 38)\nmachine-2-2 test machine-2-2.txt (23700, 38)\nmachine-2-2 test_label machine-2-2.txt (23700,)\nmachine-1-2 train machine-1-2.txt (23694, 38)\nmachine-1-2 test machine-1-2.txt (23694, 38)\nmachine-1-2 test_label machine-1-2.txt (23694,)\nmachine-3-4 train machine-3-4.txt (23687, 38)\nmachine-3-4 test machine-3-4.txt (23687, 38)\nmachine-3-4 test_label machine-3-4.txt (23687,)\nmachine-3-3 train machine-3-3.txt (23703, 38)\nmachine-3-3 test machine-3-3.txt (23703, 38)\nmachine-3-3 test_label machine-3-3.txt (23703,)\nmachine-3-2 train machine-3-2.txt (23702, 38)\nmachine-3-2 test machine-3-2.txt (23703, 38)\nmachine-3-2 test_label machine-3-2.txt (23703,)\nmachine-1-7 train machine-1-7.txt (23697, 38)\nmachine-1-7 test machine-1-7.txt (23697, 38)\nmachine-1-7 test_label machine-1-7.txt (23697,)\nmachine-1-4 train machine-1-4.txt (23706, 38)\nmachine-1-4 test machine-1-4.txt (23707, 38)\nmachine-1-4 test_label machine-1-4.txt (23707,)\nmachine-3-8 train machine-3-8.txt (28703, 38)\nmachine-3-8 test machine-3-8.txt (28704, 38)\nmachine-3-8 test_label machine-3-8.txt (28704,)\nmachine-1-8 train machine-1-8.txt (23698, 38)\nmachine-1-8 test machine-1-8.txt (23699, 38)\nmachine-1-8 test_label machine-1-8.txt (23699,)\nmachine-2-5 train machine-2-5.txt (23688, 38)\nmachine-2-5 test machine-2-5.txt (23689, 38)\nmachine-2-5 test_label machine-2-5.txt (23689,)\nmachine-2-4 train machine-2-4.txt (23689, 38)\nmachine-2-4 test machine-2-4.txt (23689, 38)\nmachine-2-4 test_label machine-2-4.txt (23689,)\nmachine-2-6 train machine-2-6.txt (28743, 38)\nmachine-2-6 test machine-2-6.txt (28743, 38)\nmachine-2-6 test_label machine-2-6.txt (28743,)\nmachine-1-3 train machine-1-3.txt (23702, 38)\nmachine-1-3 test machine-1-3.txt (23703, 38)\nmachine-1-3 test_label machine-1-3.txt (23703,)\nDone loading and pre-processing SMD into pkl files.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import time # for training stats\n",
        "\n",
        "# Class to measure the time taken for each epoch during training / fine stats\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "# Create a general Output directory to store results\n",
        "results_dir = '/kaggle/working/results2/'\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Initialize a list to store the history objects and training times per model (external to the loops)\n",
        "# Store the total training time and history object\n",
        "histories = []\n",
        "total_training_times = [] #aggregated stat, coarse\n",
        "performance_metrics = []\n",
        "\n",
        "# List of model names\n",
        "# model_names = [\"snu-ae\", \"snu-transformer\", \"lstm\", \"transformer\"]\n",
        "model_names = [\"lstm\", \"transformer\"]\n",
        "\n",
        "# Define a dictionary for model indices used for Loop#2; default range(4), or less for quick trials\n",
        "model_indices = {\n",
        "#     'snu-ae': 1,\n",
        "#     'snu-transformer': 2,\n",
        "    'lstm': 1,\n",
        "    'transformer': 2\n",
        "}\n",
        "\n",
        "# Initialize a list to store the models\n",
        "model_list = []\n",
        "\n",
        "# Initialize the TimeHistory callback, fine (external to the loops)\n",
        "time_callback = TimeHistory()\n",
        "\n",
        "# Define our callbacks common to all models (external to the loops)\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=0.00001)\n",
        "\n",
        "# Define and build our 4 (or less) AE models\n",
        "# model_builders = [build_snu_model, build_snu_transformer_AE, build_lstm_model, build_transformer_model]\n",
        "model_builders = [build_lstm_model, build_transformer_model]\n",
        "\n",
        "# Configs build: Loop over each model to configure correctly\n",
        "for Mod_i in range(2):\n",
        "    # Set the config dictionary based on the type of the model\n",
        "    if (model_builders[Mod_i] == build_snu_model) or (model_builders[Mod_i] == build_snu_transformer_AE):\n",
        "        config = {'activation': tf.nn.sigmoid, 'recurrent': True, 'decay': 0.98, 'g': tf.identity} #input_shape = (sequence_length, features) => (120,38)\n",
        "    else:\n",
        "        config =  Box({\"window_length\":120, \"num_features\":38}) # used for the plain, non-SNU models\n",
        "\n",
        "    model, early_stop = model_builders[Mod_i]()\n",
        "    callbacks = [early_stop, lr_scheduler, time_callback]\n",
        "\n",
        "    # Add the model to the model list\n",
        "    model_list.append(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:37:27.943266Z",
          "iopub.execute_input": "2024-02-23T12:37:27.943573Z",
          "iopub.status.idle": "2024-02-23T12:37:31.892127Z",
          "shell.execute_reply.started": "2024-02-23T12:37:27.943547Z",
          "shell.execute_reply": "2024-02-23T12:37:31.891266Z"
        },
        "trusted": true,
        "id": "7H8Ho5diwZSA",
        "outputId": "facad0d5-345c-4594-e20e-7a63bfd395ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 120, 128)          85504     \n                                                                 \n batch_normalization (Batch  (None, 120, 128)          512       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 120, 128)          0         \n                                                                 \n lstm_1 (LSTM)               (None, 120, 7)            3808      \n                                                                 \n batch_normalization_1 (Bat  (None, 120, 7)            28        \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 120, 7)            0         \n                                                                 \n lstm_2 (LSTM)               (None, 120, 38)           6992      \n                                                                 \n=================================================================\nTotal params: 96844 (378.30 KB)\nTrainable params: 96574 (377.24 KB)\nNon-trainable params: 270 (1.05 KB)\n_________________________________________________________________\nCompiling model...\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 120, 38)]            0         []                            \n                                                                                                  \n sine_position_encoding (Si  (None, 120, 38)              0         ['input_2[0][0]']             \n nePositionEncoding)                                                                              \n                                                                                                  \n tf.__operators__.add (TFOp  (None, 120, 38)              0         ['input_2[0][0]',             \n Lambda)                                                             'sine_position_encoding[0][0]\n                                                                    ']                            \n                                                                                                  \n transformer_encoder (Trans  (None, 120, 38)              15509     ['tf.__operators__.add[0][0]']\n formerEncoder)                                                                                   \n                                                                                                  \n dense (Dense)               (None, 120, 20)              780       ['transformer_encoder[0][0]'] \n                                                                                                  \n transformer_encoder_1 (Tra  (None, 120, 20)              7028      ['dense[0][0]']               \n nsformerEncoder)                                                                                 \n                                                                                                  \n dense_1 (Dense)             (None, 120, 7)               147       ['transformer_encoder_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n transformer_encoder_2 (Tra  (None, 120, 7)               2117      ['dense_1[0][0]']             \n nsformerEncoder)                                                                                 \n                                                                                                  \n dense_2 (Dense)             (None, 120, 20)              160       ['transformer_encoder_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n transformer_encoder_3 (Tra  (None, 120, 20)              7028      ['dense_2[0][0]']             \n nsformerEncoder)                                                                                 \n                                                                                                  \n dense_3 (Dense)             (None, 120, 32)              672       ['transformer_encoder_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n dense_4 (Dense)             (None, 120, 38)              1254      ['dense_3[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 34695 (135.53 KB)\nTrainable params: 34695 (135.53 KB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\nCompiling model...\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test labels (assuming a 1D numpy array of binary values)\n",
        "test_labels = np.loadtxt(\"/kaggle/input/smd-onmiad/ServerMachineDataset/test_label/machine-1-7.txt\")\n",
        "\n",
        "label_indexes = []\n",
        "start_timestamps = []\n",
        "end_timestamps = []\n",
        "\n",
        "# Keep track of the current start and previous label\n",
        "current_start = 0\n",
        "prev_label = None\n",
        "\n",
        "# Keep track of the current label segment and its index\n",
        "current_label = None\n",
        "segment_index = 0\n",
        "\n",
        "# Iterate through each label value\n",
        "for i, label in enumerate(test_labels):\n",
        "    # Check for label change or end of data\n",
        "    if label != prev_label or i == len(test_labels) - 1:\n",
        "        # Add information for the previous segment (if it was a 1 segment)\n",
        "        if prev_label == 1:\n",
        "            label_indexes.append(segment_index)  # Use segment_index directly\n",
        "            start_timestamps.append(current_start)\n",
        "            end_timestamps.append(i - 1)  # Adjust for zero-based indexing\n",
        "\n",
        "        # Start a new segment for the current label\n",
        "        current_start = i\n",
        "        prev_label = label\n",
        "        segment_index += 1 if label == 1 else 0  # Increment only for 1 segments\n",
        "\n",
        "# Print or store the extracted information\n",
        "print(\"Label indexes:\", label_indexes)\n",
        "print(\"Start timestamps:\", start_timestamps)\n",
        "print(\"End timestamps:\", end_timestamps)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:37:31.893271Z",
          "iopub.execute_input": "2024-02-23T12:37:31.893555Z",
          "iopub.status.idle": "2024-02-23T12:37:31.919208Z",
          "shell.execute_reply.started": "2024-02-23T12:37:31.893530Z",
          "shell.execute_reply": "2024-02-23T12:37:31.918371Z"
        },
        "trusted": true,
        "id": "usO6QYDqwZSB",
        "outputId": "57c8f300-115a-4be5-8210-91a8daa8327d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Label indexes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\nStart timestamps: [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nEnd timestamps: [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XAD = eXplainable AD, starting w/ the top culprit KPIs, to be extracted per event window\n",
        "### Currently under trials, with unstable XAD snippets for top contribs (challenges in cleaning up the code for culprit KPI identinfication per AD event, not mere avgs.)"
      ],
      "metadata": {
        "id": "beq5zTiUwZSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main / loop#1: All 28 machine names from the SMD dataset\n",
        "# machine_names = [\"machine-1-1\", \"machine-1-2\", \"machine-1-3\", \"machine-1-4\", \"machine-1-5\", \"machine-1-6\", \"machine-1-7\", \"machine-1-8\", \"machine-2-1\", \"machine-2-2\", \"machine-2-3\", \"machine-2-4\", \"machine-2-5\", \"machine-2-6\", \"machine-2-7\", \"machine-2-8\", \"machine-2-9\", \"machine-3-1\", \"machine-3-2\", \"machine-3-3\", \"machine-3-4\", \"machine-3-5\", \"machine-3-6\", \"machine-3-7\", \"machine-3-8\", \"machine-3-9\", \"machine-3-10\", \"machine-3-11\"]\n",
        "\n",
        "machine_names = [\"machine-1-7\"]\n",
        "# Loop over each machine\n",
        "for i_mach, machine_name in enumerate(machine_names):\n",
        "    dataset = f\"{machine_name}\"\n",
        "\n",
        "    (x_train, _), (x_test, y_test) = \\\n",
        "            get_data(dataset, None, None, train_start=0,\n",
        "                      test_start=0)\n",
        "\n",
        "    # Part 4c: Train & Test preps\n",
        "    # Build the SMD training dataset In == Out tensor shape for AE, batches / wndw, seq_size, stride chosen as in the SI wild dataset (SMD = 1min/step; IBM SI = 5min/step)\n",
        "    ds_train = tf.keras.utils.timeseries_dataset_from_array(\n",
        "                    data=x_train,\n",
        "                    targets=None,\n",
        "                    sequence_length=120,\n",
        "                    sequence_stride=1,\n",
        "                    sampling_rate=1,\n",
        "                    batch_size=1024,\n",
        "                    shuffle=False\n",
        "                )\n",
        "    ds_train = tf.data.Dataset.zip((ds_train, ds_train))\n",
        "\n",
        "    # Validation set build: skip stride=seq\n",
        "    ds_validation = tf.keras.utils.timeseries_dataset_from_array(\n",
        "                    data=x_test,\n",
        "                    targets=None,\n",
        "                    sequence_length=120,\n",
        "                    sequence_stride=120,\n",
        "                    sampling_rate=1,\n",
        "                    batch_size=1024,\n",
        "                    shuffle=False\n",
        "                )\n",
        "    ds_validation = tf.data.Dataset.zip((ds_validation, ds_validation))\n",
        "\n",
        "    # Define the base directory\n",
        "    base_dir = os.path.join(results_dir, machine_name)\n",
        "\n",
        "\n",
        "    # Loop#2 over each model from our 4 model list to fit them (strings needed for IO, but keras objects for work)\n",
        "    for Mod_i, model_name_str in enumerate(model_names):\n",
        "        # Second main loop#2\n",
        "        model = model_list[Mod_i]\n",
        "\n",
        "        # Start the timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Fit the model\n",
        "        history = model.fit(\n",
        "            x=ds_train,\n",
        "            validation_data=ds_validation,\n",
        "            epochs=25,\n",
        "            callbacks=callbacks,\n",
        "            workers=4,\n",
        "            max_queue_size=10,\n",
        "            batch_size=1024,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        # Stop the timer and calculate the total training time per model\n",
        "        end_time = time.time()\n",
        "        total_training_time = end_time - start_time\n",
        "\n",
        "        # Store the total training time and history object\n",
        "        total_training_times.append(total_training_time)\n",
        "        histories.append(history)\n",
        "\n",
        "        # Print the total training time and average time per epoch for the current model\n",
        "        print(f\"Total training time for Model {Mod_i+1}: {total_training_time} seconds\")\n",
        "        print(f\"Average time per epoch: {total_training_time/len(history.epoch)} seconds\")\n",
        "\n",
        "\n",
        "        machine_model_dir = os.path.join(base_dir, model_name_str)\n",
        "        os.makedirs(machine_model_dir, exist_ok=True)\n",
        "        print(\"Working dirs=\", results_dir, \"base_dir=\", base_dir, \"machine_name=\", machine_name, \"model_name_str=\", model_name_str, \"machine_model_dir=\", machine_model_dir)\n",
        "\n",
        "        # Define the metrics to plot\n",
        "        metrics = ['loss', 'val_loss', 'mse', 'val_mse', 'mae', 'val_mae']\n",
        "\n",
        "        # After fitting the model we manually extract its dictionary (could also use the defined metrics)\n",
        "        #V history_data = history.history\n",
        "        history_data = {\n",
        "            'loss': history.history['loss'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'mse': history.history['mse'],\n",
        "            'val_mse': history.history['val_mse'],\n",
        "            'mae': history.history['mae'],\n",
        "            'val_mae': history.history['val_mae']\n",
        "        }\n",
        "\n",
        "        # Now history_data is a dictionary that contains the loss and accuracy values for each epoch\n",
        "        # We pickle this dictionary instead of the whole history object\n",
        "        with open(os.path.join(machine_model_dir, f'training_data_model_{Mod_i+1}.pkl'), 'wb') as f:\n",
        "            pickle.dump({'total_training_times': total_training_times, 'history_data': history_data}, f)\n",
        "\n",
        "        #=========================================================\n",
        "           # For each metric plot and save the training perf history\n",
        "            for metric in metrics:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.plot(history_data[metric], label=f'Training {metric}')\n",
        "                if f'val_{metric}' in history_data:\n",
        "                    plt.plot(history_data[f'val_{metric}'], label=f'Validation {metric}')\n",
        "                plt.title(f'{metric.capitalize()} for Model {model_name_str} across all epochs')\n",
        "                plt.xlabel('Epoch')\n",
        "                plt.ylabel(metric.capitalize())\n",
        "                plt.legend()\n",
        "                plt.savefig(os.path.join(base_dir, f'{model_name_str}/{metric}_history_model_{Mod_i}.png'))\n",
        "                plt.close()\n",
        "\n",
        "            print(\"Training metrics saved for Server=\", machine_name, \"AE_model=\", model_name_str, \"Server&Model_dir=\", machine_model_dir)\n",
        "\n",
        "# Predict (AD) => Loop over each AE model in the model list to validate them vs. the test/validation set\n",
        "# for Mod_i in range(4):\n",
        "#     model = model_list[Mod_i]\n",
        "\n",
        "            # Final Model resulting after training, is validated vs. the GT label dataset and perf. measured (Prec, Recall, F1 ...)\n",
        "            # Prediction on validation set\n",
        "            pred = model.predict(ds_validation)\n",
        "            pred = np.vstack(\n",
        "                [np.reshape(element, (-1, 38)) for element in pred]\n",
        "            )\n",
        "\n",
        "            # Ground truth label-based validation for individual machines (brute force approach)\n",
        "            gt = np.vstack(\n",
        "                [np.reshape(element, (-1, 38)) for element in ds_validation.map(lambda x, y: x)]\n",
        "            )\n",
        "\n",
        "            # Compute squared error of the model's prediction vs. the ground truth labeled SMD dataset\n",
        "            err = np.square(gt - pred)\n",
        "            cur_signal = err\n",
        "            cur_data = gt\n",
        "            print(np.shape(cur_signal))\n",
        "\n",
        "            # Post-proc#1: Aggregate Reconstruction Errors across all KPIs and apply Telemanom optimizer for primary event detection\n",
        "            cur_signal_agg = np.sum(cur_signal, axis=1)\n",
        "            cur_signal_agg_ma = (\n",
        "                pd.DataFrame(cur_signal_agg)\n",
        "                .ewm(span=12)\n",
        "                .mean()\n",
        "                .values.flatten()\n",
        "            )\n",
        "\n",
        "            # Run Telemanom (TLM) for AD on the AE reconstruct_errors and obtain AD windows, aka. raw event intervals\n",
        "            errors = Errors(cur_signal_agg_ma, cur_signal, cur_data)\n",
        "            errors.process_batches()\n",
        "            cur_idx_starts = [novelty_window[0] for novelty_window in errors.E_seq]\n",
        "            cur_idx_ends = [novelty_window[-1] for novelty_window in errors.E_seq]\n",
        "\n",
        "            # Print the event intervals\n",
        "            print(cur_idx_starts)\n",
        "            print(cur_idx_ends)\n",
        "\n",
        "            # Plot binary array for anomaly intervals\n",
        "            import numpy as np\n",
        "            import matplotlib.pyplot as plt\n",
        "            anomaly_intervals = np.zeros(max(cur_idx_ends) + 1)\n",
        "            for start, end in zip(cur_idx_starts, cur_idx_ends):\n",
        "                anomaly_intervals[start:end+1] = 1\n",
        "\n",
        "            #print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "            plt.figure(figsize=(10, 3))\n",
        "            plt.plot(anomaly_intervals)\n",
        "            plt.title(\"Predicted Anomaly Intervals\")\n",
        "            plt.xlabel(\"Time Step\")\n",
        "            plt.ylabel(\"Anomaly\")\n",
        "            #plt.show()\n",
        "\n",
        "            # Save the plot to a file\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'anomaly_intervals_model_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "\n",
        "            # Calculate the raw/many AD event_durations before refinement in PPS#2 ?\n",
        "            # Convert event window indexes into 0s for normal and 1s for raw AD events (raw: after only the primary detection AE+TLM)\n",
        "            pred = np.zeros(np.shape(y_test))\n",
        "\n",
        "            # To be done per event: Assuming event_duration is the average duration of our detected anomaly events\n",
        "            # event_duration = np.mean(np.array(cur_idx_ends) - np.array(cur_idx_starts))\n",
        "            # event_duration = int(event_duration)  # Convert to integer if needed\n",
        "            event_duration = np.mean(np.array(cur_idx_ends) - np.array(cur_idx_starts)).astype(int)\n",
        "            print(\"Average raw event duration:\", event_duration)\n",
        "\n",
        "            for i, start in enumerate(cur_idx_starts):\n",
        "                end = cur_idx_ends[i] + 1\n",
        "                pred[start:end] = 1\n",
        "\n",
        "            # Calculate AE-based reconstruction errors\n",
        "            rec_err = np.mean(err, axis=1)\n",
        "            np.shape(rec_err)\n",
        "\n",
        "            # Descriptive statistics of reconstruction errors\n",
        "            pd.Series(rec_err).describe()\n",
        "\n",
        "            # XAD defs\n",
        "            # Generic KPI contributions functions to be recoded\n",
        "            def calculate_kpi_contributions(models, data):\n",
        "                \"\"\"Calculate KPI contributions to reconstruction errors.\"\"\"\n",
        "                mse_list, kpi_contributions_list = [], []\n",
        "\n",
        "                for model in models:\n",
        "                    reconstructions = model.predict(data)\n",
        "                    mse = np.mean(np.square(data - reconstructions), axis=(1, 2))\n",
        "                    kpi_contributions = np.mean(np.abs(data - reconstructions), axis=(0, 1))\n",
        "\n",
        "                    mse_list.append(mse)\n",
        "                    kpi_contributions_list.append(kpi_contributions)\n",
        "\n",
        "                return mse_list, kpi_contributions_list\n",
        "\n",
        "            def accumulate_kpi_contributions(kpi_contributions_list, event_duration):\n",
        "                \"\"\"Accumulate KPI contributions over the entire event duration.\"\"\"\n",
        "                accumulated_contributions = np.zeros_like(kpi_contributions_list[0])\n",
        "                min_length = min(event_duration, len(kpi_contributions_list)) # TBD per each event: event_duration = np.mean(np.array(cur_idx_ends) - np.array(cur_idx_starts)).astype(int)\n",
        "\n",
        "                for i in range(min_length):\n",
        "                    current_contributions = kpi_contributions_list[i]\n",
        "                    accumulated_contributions += current_contributions\n",
        "                    contributing_kpis = np.where(current_contributions > 0)[0] + 1  # Adding 1 to convert from zero-based to one-based index\n",
        "#                     print(f\"Step {i + 1} contributing KPIs:\", contributing_kpis)\n",
        "#                     for kpi_index in contributing_kpis:\n",
        "#                         print(f\"  KPI {kpi_index} contribution: {current_contributions[kpi_index - 1]}\")\n",
        "                print(\"Accumulated contribs/KPI:\", accumulated_contributions)\n",
        "\n",
        "                return accumulated_contributions\n",
        "\n",
        "\n",
        "            # Assuming x_test has shape (~28k steps, 38 KPIs)\n",
        "            desired_sequence_length = config['window_length']  # 120\n",
        "            num_features = config['num_features']  # 38\n",
        "            # Calculate the number of sequences we can create\n",
        "            num_sequences = len(x_test) // desired_sequence_length\n",
        "            # Calculate the number of elements to pad\n",
        "            remaining_elements = len(x_test) % desired_sequence_length\n",
        "            elements_to_pad = desired_sequence_length - remaining_elements\n",
        "            # Pad the array with zeros\n",
        "            x_test_padded = np.pad(x_test, ((0, elements_to_pad), (0, 0)), mode='constant')\n",
        "            # Reshape the padded array\n",
        "            x_test_reshaped = x_test_padded.reshape((num_sequences + 1, desired_sequence_length, num_features))\n",
        "\n",
        "            # Extract top KPI contribs\n",
        "            # Calculate KPI contributions for the SMD test dataset\n",
        "            test_mse_list, test_kpi_contributions_list = calculate_kpi_contributions(model_list, x_test_reshaped)\n",
        "            # x_test.reshape((-1, config['window_length'], config['num_features'])))\n",
        "\n",
        "            # Access the top contributing KPIs during anomaly events of avg duration\n",
        "            accumulated_contributions = accumulate_kpi_contributions(test_kpi_contributions_list, event_duration)\n",
        "            top_contributors = np.argsort(accumulated_contributions)[::-1][:10]\n",
        "            print(\"Culprit KPIs for all AD events of\", machine_name, \"Top-k=\", top_contributors)\n",
        "\n",
        "\n",
        "            # Compute AUROC, albeit less relevant here\n",
        "            from sklearn.metrics import roc_auc_score\n",
        "            roc_auc_score(y_test[:len(rec_err)], rec_err)\n",
        "\n",
        "            # Set an heuristic/SME-based threshold for anomaly (pre-)classification\n",
        "            thresh = 0.05\n",
        "            label_pred = [1 if x >= thresh else 0 for x in rec_err]\n",
        "\n",
        "            # Calculate the initial precision, recall, F1-score, and support;\n",
        "            # also handling the \"no predicted AD samples\" rare case, which leads to zero_division\n",
        "            P_bef, R_bef, F1_bef, _ = precision_recall_fscore_support(\n",
        "                y_test[:len(label_pred)], label_pred, average=\"binary\", zero_division=0\n",
        "            )\n",
        "\n",
        "            # Plot model's rec_err with a logarithmic scale on the Y-axis\n",
        "            rec_err_normal = [x for i, x in enumerate(rec_err) if label_pred[i] == 0]\n",
        "            rec_err_anomaly = [x for i, x in enumerate(rec_err) if label_pred[i] == 1]\n",
        "\n",
        "            #print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.hist(rec_err_normal, bins=250, color='blue', alpha=0.95)\n",
        "            plt.hist(rec_err_anomaly, bins=250, color='red', alpha=1)\n",
        "            plt.yscale('log')\n",
        "            plt.xlabel('Reconstruction Error')\n",
        "            plt.ylabel('Frequency (log scale)')\n",
        "            plt.title('Histogram of AE Model\\'s Reconstruction Errors')\n",
        "            plt.grid()\n",
        "            #plt.show()\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'reconstruction_errors_histogram_model_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "\n",
        "            # AD events detected before aggregation\n",
        "            AD_events = np.sum(label_pred)\n",
        "            print(\"AD_events detected =>\", AD_events )\n",
        "\n",
        "\n",
        "            # v3: Post-proc#2 (PPS2): AD windows' aggregation for bursty events\n",
        "            def adjust_pred(test_true, test_pred):\n",
        "              \"\"\"\n",
        "              Adjusts predicted anomaly labels based on true labels and event durations.\n",
        "\n",
        "              Args:\n",
        "                  test_true: A list of true anomaly labels (0: normal, 1: anomaly).\n",
        "                  test_pred: A list of predicted anomaly labels (0: normal, 1: anomaly).\n",
        "\n",
        "              Returns:\n",
        "                  A tuple containing:\n",
        "                      - Adjusted predicted anomaly labels (`test_pred_adjusted`).\n",
        "                      - List of anomaly event start indices (`event_starts`).\n",
        "                      - List of anomaly event end indices (`event_ends`).\n",
        "              \"\"\"\n",
        "\n",
        "              # Initialize variables\n",
        "              print(\"Evaluation: Adjusting predictions ...\")\n",
        "              anomaly_state = False\n",
        "              event_starts = []\n",
        "              event_ends = []\n",
        "\n",
        "              # Iterate through each label pair\n",
        "              for i, (true_label, pred_label) in enumerate(zip(test_true, test_pred)):\n",
        "                # Check for start of an anomaly event\n",
        "                if true_label == 1 and pred_label == 1 and not anomaly_state:\n",
        "                  anomaly_state = True\n",
        "                  event_starts.append(i)\n",
        "\n",
        "                # Check for end of an anomaly event\n",
        "                elif true_label == 0 and anomaly_state:\n",
        "                  anomaly_state = False\n",
        "                  event_ends.append(i - 1)\n",
        "\n",
        "              # Handle potential last event extending to the end\n",
        "              if anomaly_state:\n",
        "                event_ends.append(len(test_true) - 1)\n",
        "\n",
        "              # Adjust predictions based on event durations\n",
        "              test_pred_adjusted = test_pred.copy()  # Avoid modifying original list\n",
        "              for start, end in zip(event_starts, event_ends):\n",
        "                # Extend anomaly prediction backward until true non-anomaly\n",
        "                for j in range(start, 0, -1):\n",
        "                  if test_true[j] == 0:\n",
        "                    break\n",
        "                  if test_pred_adjusted[j] == 0:\n",
        "                    test_pred_adjusted[j] = 1\n",
        "\n",
        "                # Extend anomaly prediction forward until true non-anomaly\n",
        "                for j in range(end, len(test_true)):\n",
        "                  if test_true[j] == 0:\n",
        "                    break\n",
        "                  if test_pred_adjusted[j] == 0:\n",
        "                    test_pred_adjusted[j] = 1\n",
        "\n",
        "              # Print informative message => GT_labels\n",
        "              print(\"Adjustment completed; event starts\", event_starts)\n",
        "              print(\"Adjustment completed; event ends\", event_ends)\n",
        "              return test_pred_adjusted, event_starts, event_ends\n",
        "\n",
        "\n",
        "            # AD events resulted after bursty AD post-proc#2, aggregated => predict events\n",
        "            label_pred, event_starts, event_ends = adjust_pred(y_test[:len(label_pred)], label_pred)   #? => all the GT_labels\n",
        "            AD_events_aggregated = np.sum(label_pred) #? => GT_labels - 4 events (M1-7)\n",
        "            # AD_events_aggregated = len(event_starts) # gt_labels-few ?\n",
        "\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "            print(\"AD_events_aggregated in pps2 => \", AD_events_aggregated)\n",
        "            print(\"Start of aggregated AD events:\", event_starts)\n",
        "            print(\"Ends  of aggregated AD events:\", event_ends)\n",
        "\n",
        "\n",
        "            # Ensure y_test is in the correct format (convert to list if necessary)\n",
        "            from sklearn.preprocessing import MultiLabelBinarizer\n",
        "            y_test_list = y_test.tolist() if isinstance(y_test, np.ndarray) else y_test\n",
        "\n",
        "            # Convert true labels to binary format\n",
        "            mlb = MultiLabelBinarizer()\n",
        "            try:\n",
        "                y_test_binary = mlb.fit_transform(y_test_list)\n",
        "            except TypeError:\n",
        "                # If TypeError occurs, y_test_list may contain float values\n",
        "                y_test_binary = np.array(y_test_list).reshape(-1, 1)\n",
        "\n",
        "            # Assuming rec_err is a numpy array\n",
        "            min_rec_err = np.min(rec_err)\n",
        "            max_rec_err = np.max(rec_err)\n",
        "            num_thresholds = 5  # adjust me...\n",
        "\n",
        "            # Create thresholds within the range of rec_err\n",
        "            thresholds = np.linspace(min_rec_err, max_rec_err, num=num_thresholds)\n",
        "\n",
        "            # Use y_test_binary instead of y_test\n",
        "            for i, threshold in enumerate(thresholds):\n",
        "                label_pred = [1 if x >= threshold else 0 for x in rec_err]\n",
        "                label_pred, _, _ = adjust_pred(y_test_binary[:len(label_pred)], label_pred)\n",
        "                p[i], r[i], f1[i], _ = precision_recall_fscore_support(\n",
        "                    y_test_binary[:len(label_pred)], label_pred, average=\"binary\", zero_division=0\n",
        "                )\n",
        "\n",
        "            def calculate_individual_kpi_means(data):\n",
        "                \"\"\"Calculates the mean of each KPI across all data.\"\"\"\n",
        "                return np.mean(data, axis=(0, 1))\n",
        "\n",
        "            def calculate_total_error_in_window(data, reconstructions):\n",
        "                \"\"\"Calculates the total error in each window of data.\"\"\"\n",
        "                return np.sum(np.square(data - reconstructions), axis=(1, 2))\n",
        "\n",
        "            def calculate_kpi_contributions_per_event(model, data):\n",
        "                \"\"\"Calculates MSE and KPI contributions within an event window.\"\"\"\n",
        "                # Ensure data is not empty\n",
        "                if data.shape[1] > 0:\n",
        "                    reconstructions = model.predict(data)\n",
        "                    mse = np.mean(np.square(data - reconstructions), axis=(1, 2))\n",
        "                    kpi_contributions = np.mean(np.abs(data - reconstructions), axis=(0, 1))\n",
        "                else:\n",
        "                    print(f\"Invalid event window: data is empty\")\n",
        "                    mse = None\n",
        "                    kpi_contributions = None\n",
        "\n",
        "                return mse, kpi_contributions\n",
        "\n",
        "            def accumulate_kpi_contributions_normalized(kpi_contributions_list, event_durations, individual_kpi_means, total_error_in_window):\n",
        "                \"\"\"Accumulates and normalizes KPI contributions per event.\"\"\"\n",
        "                accumulated_contributions = np.zeros_like(kpi_contributions_list[0])\n",
        "\n",
        "                for i, (event_contributions, event_duration) in enumerate(zip(kpi_contributions_list, event_durations)):\n",
        "                    normalized_contributions = event_contributions / (individual_kpi_means[i] or total_error_in_window[i])\n",
        "                    accumulated_contributions += normalized_contributions[:event_duration]\n",
        "\n",
        "                    # Logic for identifying and printing top contributing KPIs per event\n",
        "                    contributing_kpis = np.where(normalized_contributions > 0)[0] + 1  # Adding 1 to convert from zero-based to one-based index\n",
        "                    print(f\"Event {i + 1} contributing KPIs:\", contributing_kpis)\n",
        "                    for kpi_index in contributing_kpis:\n",
        "                        print(f\"  KPI {kpi_index} contribution: {normalized_contributions[kpi_index - 1]}\")\n",
        "\n",
        "                print(\"Accumulated contributions for each KPI:\", accumulated_contributions)\n",
        "                return accumulated_contributions\n",
        "\n",
        "                # Calculate the individual KPI means and total error in window\n",
        "                individual_kpi_means = calculate_individual_kpi_means(x_test_reshaped)\n",
        "                total_error_in_window = calculate_total_error_in_window(x_test_reshaped, model.predict(x_test_reshaped))\n",
        "\n",
        "                # Calculate the sequence index and offset for each event start and end\n",
        "                event_starts_seq_idx = [start // desired_sequence_length for start in event_starts]\n",
        "                event_starts_offset = [start % desired_sequence_length for start in event_starts]\n",
        "                event_ends_seq_idx = [end // desired_sequence_length for end in event_ends]\n",
        "                event_ends_offset = [end % desired_sequence_length for end in event_ends]\n",
        "                print(f\"Number of events: {len(event_starts)}\")\n",
        "\n",
        "                # Iterate over aggregated events and calculate/accumulate KPI contributions\n",
        "                for i in range(len(event_starts)):\n",
        "                    start_seq_idx, start_offset = event_starts_seq_idx[i], event_starts_offset[i]\n",
        "                    end_seq_idx, end_offset = event_ends_seq_idx[i], event_ends_offset[i]\n",
        "                    print(f\"Processing event {i+1}\")\n",
        "\n",
        "                    # Extract the sequences and offsets for the current event\n",
        "                    event_sequences = x_test_reshaped[start_seq_idx:end_seq_idx+1]\n",
        "                    if start_seq_idx == end_seq_idx:\n",
        "                        # If the event is within a single sequence, slice it out\n",
        "                        event_data = event_sequences[:, start_offset:end_offset, :]\n",
        "                    else:\n",
        "                        # If the event spans multiple sequences, slice out the first and last sequences and concatenate\n",
        "                        first_sequence = event_sequences[0, start_offset:, :]\n",
        "                        last_sequence = event_sequences[-1, :end_offset, :]\n",
        "                        middle_sequences = event_sequences[1:-1] if len(event_sequences) > 2 else np.array([])\n",
        "                        if middle_sequences.size > 0:\n",
        "                            # Flatten middle_sequences along the sequence dimension\n",
        "                            middle_sequences = middle_sequences.reshape(-1, middle_sequences.shape[-1])\n",
        "                        event_data = np.concatenate([first_sequence, middle_sequences, last_sequence], axis=0) if middle_sequences.size > 0 else np.concatenate([first_sequence, last_sequence], axis=0)\n",
        "\n",
        "                    # Ensure event_data has a 3D shape\n",
        "                    if len(event_data.shape) < 3:\n",
        "                        event_data = np.expand_dims(event_data, axis=0)\n",
        "\n",
        "                    mse, kpi_contributions = calculate_kpi_contributions_per_event(model, event_data)\n",
        "                    if kpi_contributions is not None:\n",
        "                        # Additional logic for normalizing and accumulating KPI contributions\n",
        "                        normalized_contributions = kpi_contributions / (individual_kpi_means[i] or total_error_in_window[i])\n",
        "                        if i == 0:\n",
        "                            # Initialize accumulated_contributions with the correct shape\n",
        "                            accumulated_contributions = np.zeros_like(normalized_contributions)\n",
        "                        accumulated_contributions += normalized_contributions\n",
        "                        # Access the top contributing KPIs per AD event\n",
        "                        top_contributors = np.argsort(accumulated_contributions)[::-1][:10]\n",
        "                        print(f\"Event {i+1}: Top-k contributing KPIs={top_contributors}\")\n",
        "                    else:\n",
        "                        print(f\"KPI contributions could not be calculated for event {i+1}\")\n",
        "\n",
        "\n",
        "            # Plot test labels and refined predicted events\n",
        "            #machine_name = dataset\n",
        "            label_file_path = f\"/kaggle/working/ServerMachineDataset/processed/{machine_name}_test_label.pkl\"\n",
        "            gt_labels = pd.read_pickle(label_file_path)\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "\n",
        "            plt.figure(figsize=(22, 4))\n",
        "            plt.plot(label_pred, alpha=0.7, label=\"Refined Predicted AD Events\")\n",
        "            plt.plot(gt_labels, alpha=0.9, label=\"Test Labels\")\n",
        "            plt.title(\"Test Labels (orange) vs Refined Predicted AD Events (blue) \")\n",
        "            plt.xlabel(\"Time Step\")\n",
        "            plt.ylabel(\"Label\")\n",
        "            #plt.show()\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'Refined_AD_vs_GT_model_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "\n",
        "            # Plot model's rec_err with a logarithmic scale on the Y-axis\n",
        "            rec_err_normal = [x for i, x in enumerate(rec_err) if label_pred[i] == 0]\n",
        "            rec_err_anomaly = [x for i, x in enumerate(rec_err) if label_pred[i] == 1]\n",
        "\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.hist(rec_err_normal, bins=250, color='blue', alpha=0.8)\n",
        "            plt.hist(rec_err_anomaly, bins=250, color='red', alpha=1)\n",
        "            plt.yscale('log')\n",
        "            plt.xlabel('Reconstruction Error')\n",
        "            plt.ylabel('Frequency (log scale)')\n",
        "            plt.title('Histogram of AE Model\\'s Processed Reconstruction Errors')\n",
        "            plt.grid()\n",
        "            #plt.show()\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'Histogram_recErr_model_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "            def calculate_metrics_with_thresholds(rec_err, y_test, F_score_thresholds):\n",
        "                \"\"\"\n",
        "                Calculate precision, recall, and F1 score for different thresholds based on standard deviations.\n",
        "\n",
        "                Parameters:\n",
        "                - rec_err (numpy array): Reconstruction errors.\n",
        "                - y_test (numpy array or list): Ground truth labels (binary time series).\n",
        "                - F_score_thresholds (list): List of standard deviation multipliers for threshold calculation.\n",
        "\n",
        "                Returns:\n",
        "                - metrics (numpy array): Array containing precision, recall, and F1 score for each threshold.\n",
        "                \"\"\"\n",
        "                # Ensure y_test is in the correct format (convert to list if necessary)\n",
        "                y_test_list = y_test.tolist() if isinstance(y_test, np.ndarray) else y_test\n",
        "\n",
        "                # Assuming rec_err is a numpy array\n",
        "                min_rec_err = np.min(rec_err)\n",
        "                max_rec_err = np.max(rec_err)\n",
        "\n",
        "                # Create thresholds within the range of rec_err\n",
        "                thresholds = np.linspace(min_rec_err, max_rec_err, num=len(F_score_thresholds))\n",
        "\n",
        "                # Initialize arrays to store metrics\n",
        "                num_thresholds = len(thresholds)\n",
        "                metrics = np.zeros((num_thresholds, 3))  # 3 columns for precision, recall, F1 score\n",
        "\n",
        "                # Use y_test directly (no need for MultiLabelBinarizer)\n",
        "                for i, threshold in enumerate(thresholds):\n",
        "                    label_pred = [1 if x >= threshold else 0 for x in rec_err]\n",
        "                    label_pred, _, _ = adjust_pred(y_test[:len(label_pred)], label_pred)\n",
        "                    p, r, f1, _ = precision_recall_fscore_support(\n",
        "                        y_test[:len(label_pred)], label_pred, average=\"binary\", zero_division=0\n",
        "                    )\n",
        "                    metrics[i] = [p, r, f1]\n",
        "\n",
        "                return metrics\n",
        "\n",
        "            # Example usage:\n",
        "            F_score_thresholds = [2, 3, 4, 5, 6, 7]\n",
        "            metrics_result = calculate_metrics_with_thresholds(rec_err, y_test, F_score_thresholds)\n",
        "            print(\"F_score funct.\", metrics_result)\n",
        "\n",
        "\n",
        "            # Recalculate F1, Precision, and Recall for different cutoffs based on simple std. deviations\n",
        "            F_score_thshld = [2, 3, 4, 5, 6, 7]\n",
        "            f1 = np.zeros(len(F_score_thshld))\n",
        "            p = np.zeros(len(F_score_thshld))\n",
        "            r = np.zeros(len(F_score_thshld))\n",
        "            err_std = np.std(rec_err)\n",
        "\n",
        "            for i, k in enumerate(F_score_thshld):\n",
        "                t = np.mean(rec_err) + k * err_std\n",
        "                label_pred = [1 if x >= t else 0 for x in rec_err]\n",
        "                label_pred, _, _ = adjust_pred(y_test_binary[:len(label_pred)], label_pred)\n",
        "                p[i], r[i], f1[i], _ = precision_recall_fscore_support(\n",
        "                    y_test_binary[:len(label_pred)], label_pred, average=\"binary\", zero_division=0\n",
        "                )\n",
        "\n",
        "                from sklearn.preprocessing import MultiLabelBinarizer\n",
        "                from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "            # Print scores before and after AD event aggregation\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "            print(\"Scores before AD event aggregation\")\n",
        "            print('Prec=', P_bef, 'Rec=', R_bef, 'F1=', F1_bef)\n",
        "            print(\"========================================================================= \\n\")\n",
        "            print(\"Scores after AD event aggregation and k-sigma = [2,3,4,5,6,7,8] thresholding\")\n",
        "            print(\"Prec=\", p)\n",
        "            print(\"Rec=\", r)\n",
        "            print(\"F1=\", f1)\n",
        "\n",
        "            # Plot precision, recall, and F1 vs. thresholds\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.plot(F_score_thshld, p, marker='o', linestyle='-', label='Precision')\n",
        "            plt.plot(F_score_thshld, r, marker='o', linestyle='-', label='Recall')\n",
        "            plt.plot(F_score_thshld, f1, marker='o', linestyle='-', label='F1')\n",
        "            plt.xlabel('Thresholds')\n",
        "            plt.ylabel('Score')\n",
        "            plt.title('Precision, Recall, and F1 vs. Thresholds')\n",
        "            plt.legend()\n",
        "            plt.grid()\n",
        "            #plt.show()\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'F1_scores_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "\n",
        "            # Print F1 scores\n",
        "            # print(f1)\n",
        "\n",
        "            # Append and save the AD prediction performance metrics per machine and model\n",
        "            performance_metrics.append({\n",
        "                'P_bef': P_bef,\n",
        "                'R_bef': R_bef,\n",
        "                'F1_bef': F1_bef,\n",
        "                'p': p,\n",
        "                'r': r,\n",
        "                'f1': f1\n",
        "            })\n",
        "\n",
        "            # Save performance metrics to a pickle file for internal use; later we'll save the aggregates into one CSV file\n",
        "            with open(os.path.join(machine_model_dir, f'performance_metrics_model_{Mod_i+1}.pkl'), 'wb') as f:\n",
        "                pickle.dump(performance_metrics[-1], f)\n",
        "\n",
        "            #=========================================================================================\n",
        "            # KPI Visualisations for train & validation reconstructions vs. the original resp. KPIs\n",
        "            # Take one batch from the training dataset\n",
        "            batch = [batch[0] for i, batch in enumerate(ds_train) if i == 0]\n",
        "\n",
        "            # Check the shape of the selected batch\n",
        "            np.shape(batch)  # This should display (1, 1024, 120, 38)\n",
        "\n",
        "            # Predict using the model and the selected batch\n",
        "            batch_pred = model.predict(batch[0])\n",
        "\n",
        "            # Check the shape of the prediction\n",
        "            print(batch_pred.shape)\n",
        "\n",
        "            # Subsample every 120 time steps in the second dimension, reducing it from 1024 to 9\n",
        "            batch_pred = batch_pred[::120, :, :]\n",
        "\n",
        "            # Check the shape after subsampling\n",
        "            print(batch_pred.shape)\n",
        "\n",
        "            # Combine all 9 blocks of data into a single long array with 38 features for each of the 1080 samples\n",
        "            batch_pred = batch_pred.reshape((-1, 38))\n",
        "\n",
        "            # Check the final shape\n",
        "            print(batch_pred.shape)\n",
        "\n",
        "            # Calculate the new size by finding how many complete groups of 38 elements fit within the original size\n",
        "            curr_pred_shape = np.shape(pred)\n",
        "            new_size = ( curr_pred_shape[0] // 38) * 38\n",
        "            pred = pred[:new_size]\n",
        "\n",
        "            # Reshape the tensor to have 38 columns while inferring the number of rows to maintain the total number of elements\n",
        "            pred = tf.reshape(pred, (-1, 38))\n",
        "\n",
        "            print(pred)\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "\n",
        "            # KPIs train & validation reconstructions (): Combined plots of IN vs. OUT/predicted KPIs\n",
        "            plt.rcParams[\"figure.figsize\"] = (30, 30)\n",
        "\n",
        "            fig, ax = plt.subplots(38, 1)\n",
        "            gt_data = np.array(batch[0][::120, :, :]).reshape((-1, 38))\n",
        "\n",
        "            for i in range(38):\n",
        "                ax[i].plot(gt_data[:1000, i], label=\"IN\", color=\"red\")\n",
        "                ax[i].plot(batch_pred[:1000, i], label=\"Pred\", color=\"blue\")\n",
        "                ax[i].set_ylabel(f\"TKPI {i+1}\")\n",
        "                ax[i].legend()\n",
        "\n",
        "            #plt.show()\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'KPIs_train_model_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "\n",
        "            # Take one batch from the test/validation dataset\n",
        "            batch = [batch[0] for i, batch in enumerate(ds_validation) if i == 0]\n",
        "\n",
        "            # Check the shape of the selected batch\n",
        "            np.shape(batch)  # This should display (1, 1024, 120, 38)\n",
        "\n",
        "            # Predict using the model and the selected batch\n",
        "            batch_pred = model.predict(batch[0])\n",
        "\n",
        "            # Check the shape of the prediction\n",
        "            print(batch_pred.shape)\n",
        "\n",
        "            # Subsample every 120 time steps in the second dimension, reducing it from 1024 to 9\n",
        "            batch_pred = batch_pred[::120, :, :]\n",
        "\n",
        "            # Check the shape after subsampling\n",
        "            print(batch_pred.shape)\n",
        "\n",
        "            # Combine all 9 blocks of data into a single long array with 38 features for each of the 1080 samples\n",
        "            batch_pred = batch_pred.reshape((-1, 38))\n",
        "\n",
        "            # Check the final shape\n",
        "            print(batch_pred.shape)\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "\n",
        "            # Calculate the new size by finding how many complete groups of 38 elements fit within the original size\n",
        "            curr_pred_shape = np.shape(pred)\n",
        "            new_size = ( curr_pred_shape[0] // 38) * 38\n",
        "            pred = pred[:new_size]\n",
        "\n",
        "            # Reshape the tensor to have 38 columns while inferring the number of rows to maintain the total number of elements\n",
        "            pred = tf.reshape(pred, (-1, 38))\n",
        "\n",
        "            print(pred)\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n",
        "\n",
        "            # KPIs train & validation reconstructions (): Combined plots of IN vs. OUT/predicted KPIs\n",
        "            plt.rcParams[\"figure.figsize\"] = (30, 30)\n",
        "\n",
        "            fig, ax = plt.subplots(38, 1)\n",
        "            gt_data = np.array(batch[0][::120, :, :]).reshape((-1, 38))\n",
        "\n",
        "            for i in range(38):\n",
        "                ax[i].plot(gt_data[:1000, i], label=\"IN\", color=\"red\")\n",
        "                ax[i].plot(batch_pred[:1000, i], label=\"Pred\", color=\"blue\")\n",
        "                ax[i].set_ylabel(f\"VKPI {i+1}\")\n",
        "                ax[i].legend()\n",
        "\n",
        "            #plt.showvalid\n",
        "            plt.savefig(os.path.join(machine_model_dir, f'KPIs_valid_model_{Mod_i+1}.png'))\n",
        "            plt.close()\n",
        "            print(f\"Model {Mod_i+1} is {model.name}\")\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-23T13:28:49.525092Z",
          "iopub.execute_input": "2024-02-23T13:28:49.525481Z",
          "iopub.status.idle": "2024-02-23T13:32:40.026662Z",
          "shell.execute_reply.started": "2024-02-23T13:28:49.525452Z",
          "shell.execute_reply": "2024-02-23T13:32:40.025685Z"
        },
        "trusted": true,
        "id": "gcgUncSBwZSE",
        "outputId": "64307d2f-4195-4438-ce8c-6cb8e41d5c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "load data of: machine-1-7\ntrain:  0 None\ntest:  0 None\ntrain set shape:  (23697, 38)\ntest set shape:  (23697, 38)\ntest set label shape:  (23697,)\nEpoch 1/25\n24/24 [==============================] - 3s 106ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0470 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0431 - lr: 0.1000\nEpoch 2/25\n24/24 [==============================] - 2s 99ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0493 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0582 - lr: 0.1000\nEpoch 3/25\n24/24 [==============================] - 2s 98ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0469 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0603 - lr: 0.1000\nEpoch 4/25\n24/24 [==============================] - 2s 101ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0465 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0571 - lr: 0.1000\nEpoch 5/25\n24/24 [==============================] - 2s 96ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0475 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0443 - lr: 0.1000\nEpoch 6/25\n23/24 [===========================>..] - ETA: 0s - loss: 0.0072 - mse: 0.0072 - mae: 0.0472Restoring model weights from the end of the best epoch: 1.\n24/24 [==============================] - 3s 102ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0473 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0424 - lr: 0.1000\nEpoch 6: early stopping\nTotal training time for Model 1: 15.1683828830719 seconds\nAverage time per epoch: 2.5280638138453164 seconds\nWorking dirs= /kaggle/working/results2/ base_dir= /kaggle/working/results2/machine-1-7 machine_name= machine-1-7 model_name_str= lstm machine_model_dir= /kaggle/working/results2/machine-1-7/lstm\nTraining metrics saved for Server= machine-1-7 AE_model= lstm Server&Model_dir= /kaggle/working/results2/machine-1-7/lstm\n1/1 [==============================] - 0s 77ms/step\n(23640, 38)\n[5851, 7950, 15237, 18114]\n[5863, 7970, 15560, 18515]\nAverage raw event duration: 189\n7/7 [==============================] - 0s 9ms/step\n7/7 [==============================] - 0s 9ms/step\nAccumulated contribs/KPI: [7.36062527e-02 3.96643486e-03 5.65896742e-03 8.45376775e-03\n 1.00111496e+00 1.00257432e+00 2.36764833e-01 6.27023619e-05\n 4.69535403e-02 8.45728267e-04 1.16420304e-03 8.94404054e-02\n 6.70440495e-02 6.50074631e-02 1.24678843e-01 1.36025175e-02\n 4.80867398e-04 2.43579241e-04 1.33452803e-01 1.26291752e-01\n 1.29712045e-01 1.55699223e-01 5.16008914e-01 9.13155437e-01\n 1.41097352e-01 1.08658299e-01 6.56361663e-05 1.15689375e-01\n 2.14312677e-04 3.83288264e-02 1.51645526e-01 1.28491402e-01\n 5.73197566e-02 2.43516658e-02 1.13149777e-01 1.32483095e-01\n 4.41187003e-05 3.67615326e-06]\nCulprit KPIs for all AD events of machine-1-7 Top-k= [ 5  4 23 22  6 21 30 24 18 35]\nAD_events detected => 90\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nModel 1 is sequential\nAD_events_aggregated in pps2 =>  938\nStart of aggregated AD events: [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nEnds  of aggregated AD events: [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nAdjustment completed; event ends [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [5854, 8570, 15244, 18131]\nAdjustment completed; event ends [5939, 8579, 15269, 18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18135]\nAdjustment completed; event ends [18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18138]\nAdjustment completed; event ends [18149]\nModel 1 is sequential\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nAdjustment completed; event ends [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3120, 5854, 7143, 8570, 12371, 13800, 15243, 15960, 18120, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 5854, 7143, 8570, 15244, 18120]\nAdjustment completed; event ends [857, 5939, 7999, 8579, 15269, 18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18132]\nAdjustment completed; event ends [18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18135]\nAdjustment completed; event ends [18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18138]\nAdjustment completed; event ends [18149]\nF_score funct. [[0.10143824 1.         0.18419233]\n [0.98071625 0.14845705 0.25787758]\n [1.         0.04920767 0.09379968]\n [1.         0.01292744 0.02552491]\n [1.         0.01251043 0.0247117 ]\n [1.         0.01292744 0.02552491]]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3120, 5853, 7143, 8569, 12370, 13800, 15240, 15960, 18119, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3120, 5853, 7143, 8570, 12370, 13800, 15243, 15960, 18119, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3120, 5853, 7143, 8570, 12371, 13800, 15243, 15960, 18120, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3120, 5854, 7143, 8570, 12371, 13800, 15243, 15960, 18120, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 15960, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nModel 1 is sequential\nScores before AD event aggregation\nPrec= 0.9888888888888889 Rec= 0.03711426188490409 F1= 0.07154340836012862\n========================================================================= \n\nScores after AD event aggregation and k-sigma = [2,3,4,5,6,7,8] thresholding\nPrec= [0.3330373  0.75259875 0.96774194 0.98071625 0.99787911 0.99892589]\nRec= [0.15638032 0.15095913 0.1501251  0.14845705 0.39241034 0.38782319]\nF1= [0.21282633 0.25147621 0.2599278  0.25787758 0.5633044  0.55872634]\nModel 1 is sequential\n32/32 [==============================] - 0s 8ms/step\n(1024, 120, 38)\n(9, 120, 38)\n(1080, 38)\ntf.Tensor(\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], shape=(623, 38), dtype=float64)\nModel 1 is sequential\nModel 1 is sequential\n7/7 [==============================] - 0s 9ms/step\n(197, 120, 38)\n(2, 120, 38)\n(240, 38)\nModel 1 is sequential\ntf.Tensor(\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], shape=(608, 38), dtype=float64)\nModel 1 is sequential\nModel 1 is sequential\nEpoch 1/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0723 - mse: 0.0723 - mae: 0.1051 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.1067 - lr: 5.0000e-04\nEpoch 2/25\n24/24 [==============================] - 6s 253ms/step - loss: 0.0723 - mse: 0.0723 - mae: 0.1048 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.1061 - lr: 5.0000e-04\nEpoch 3/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0722 - mse: 0.0722 - mae: 0.1044 - val_loss: 0.0729 - val_mse: 0.0729 - val_mae: 0.1057 - lr: 5.0000e-04\nEpoch 4/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0722 - mse: 0.0722 - mae: 0.1042 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.1050 - lr: 5.0000e-04\nEpoch 5/25\n24/24 [==============================] - 6s 253ms/step - loss: 0.0722 - mse: 0.0722 - mae: 0.1038 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.1043 - lr: 5.0000e-04\nEpoch 6/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0721 - mse: 0.0721 - mae: 0.1035 - val_loss: 0.0727 - val_mse: 0.0727 - val_mae: 0.1040 - lr: 5.0000e-04\nEpoch 7/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0721 - mse: 0.0721 - mae: 0.1033 - val_loss: 0.0727 - val_mse: 0.0727 - val_mae: 0.1033 - lr: 5.0000e-04\nEpoch 8/25\n24/24 [==============================] - 6s 257ms/step - loss: 0.0721 - mse: 0.0721 - mae: 0.1030 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.1031 - lr: 5.0000e-04\nEpoch 9/25\n24/24 [==============================] - 6s 256ms/step - loss: 0.0720 - mse: 0.0720 - mae: 0.1028 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.1027 - lr: 5.0000e-04\nEpoch 10/25\n24/24 [==============================] - 6s 257ms/step - loss: 0.0720 - mse: 0.0720 - mae: 0.1026 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.1024 - lr: 5.0000e-04\nEpoch 11/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0720 - mse: 0.0720 - mae: 0.1025 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.1023 - lr: 5.0000e-04\nEpoch 12/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0720 - mse: 0.0720 - mae: 0.1023 - val_loss: 0.0725 - val_mse: 0.0725 - val_mae: 0.1019 - lr: 5.0000e-04\nEpoch 13/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0719 - mse: 0.0719 - mae: 0.1021 - val_loss: 0.0724 - val_mse: 0.0724 - val_mae: 0.1013 - lr: 5.0000e-04\nEpoch 14/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0717 - mse: 0.0717 - mae: 0.1015 - val_loss: 0.0714 - val_mse: 0.0714 - val_mae: 0.1027 - lr: 5.0000e-04\nEpoch 15/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0676 - mse: 0.0676 - mae: 0.0997 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.0916 - lr: 5.0000e-04\nEpoch 16/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0660 - mse: 0.0660 - mae: 0.0936 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.0910 - lr: 5.0000e-04\nEpoch 17/25\n24/24 [==============================] - 6s 253ms/step - loss: 0.0658 - mse: 0.0658 - mae: 0.0924 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.0915 - lr: 5.0000e-04\nEpoch 18/25\n24/24 [==============================] - 6s 256ms/step - loss: 0.0658 - mse: 0.0658 - mae: 0.0923 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0907 - lr: 5.0000e-04\nEpoch 19/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0658 - mse: 0.0658 - mae: 0.0919 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0904 - lr: 5.0000e-04\nEpoch 20/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0658 - mse: 0.0658 - mae: 0.0917 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0899 - lr: 5.0000e-04\nEpoch 21/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0657 - mse: 0.0657 - mae: 0.0914 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0897 - lr: 5.0000e-04\nEpoch 22/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0657 - mse: 0.0657 - mae: 0.0912 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.0895 - lr: 5.0000e-04\nEpoch 23/25\n24/24 [==============================] - 6s 255ms/step - loss: 0.0657 - mse: 0.0657 - mae: 0.0910 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0897 - lr: 5.0000e-04\nEpoch 24/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0657 - mse: 0.0657 - mae: 0.0909 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.0895 - lr: 5.0000e-04\nEpoch 25/25\n24/24 [==============================] - 6s 254ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.0907 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.0896 - lr: 5.0000e-04\nTotal training time for Model 2: 160.3432650566101 seconds\nAverage time per epoch: 6.413730602264405 seconds\nWorking dirs= /kaggle/working/results2/ base_dir= /kaggle/working/results2/machine-1-7 machine_name= machine-1-7 model_name_str= transformer machine_model_dir= /kaggle/working/results2/machine-1-7/transformer\nTraining metrics saved for Server= machine-1-7 AE_model= transformer Server&Model_dir= /kaggle/working/results2/machine-1-7/transformer\n1/1 [==============================] - 0s 94ms/step\n(23640, 38)\n[12365, 13794, 15236, 18114, 19560]\n[12379, 13815, 15267, 18157, 19583]\nAverage raw event duration: 26\n7/7 [==============================] - 0s 9ms/step\n7/7 [==============================] - 0s 10ms/step\nAccumulated contribs/KPI: [7.13325292e-02 3.96643486e-03 5.65896742e-03 8.46161041e-03\n 1.00111496e+00 1.00257432e+00 2.32199147e-01 6.27023619e-05\n 4.70502973e-02 8.45728267e-04 1.16420304e-03 8.96887481e-02\n 6.70440495e-02 6.23879023e-02 1.24678843e-01 1.35982782e-02\n 4.80867398e-04 2.43579241e-04 1.08524151e-01 1.05937973e-01\n 1.00183561e-01 1.24531701e-01 9.53581482e-02 9.13155437e-01\n 1.24415666e-01 1.03696644e-01 6.56361663e-05 9.14488733e-02\n 2.14312677e-04 3.83288264e-02 1.22141607e-01 1.02445938e-01\n 5.73138967e-02 2.43516658e-02 1.05637163e-01 1.05053887e-01\n 4.41187003e-05 3.79842413e-06]\nCulprit KPIs for all AD events of machine-1-7 Top-k= [ 5  4 23  6 14 21 24 30 18 19]\nAD_events detected => 22383\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nAdjustment completed; event ends [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nModel 2 is model\nAD_events_aggregated in pps2 =>  22385\nStart of aggregated AD events: [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nEnds  of aggregated AD events: [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nAdjustment completed; event ends [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3323, 5853, 7143, 8569, 12369, 13800, 15242, 15960, 18119, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18132]\nAdjustment completed; event ends [18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18138]\nAdjustment completed; event ends [18149]\nModel 2 is model\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [837, 2959, 5849, 6031, 7099, 8564, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nAdjustment completed; event ends [857, 4173, 5939, 6033, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [837, 2959, 5849, 7143, 8569, 12359, 13799, 15239, 15960, 18109, 19442, 19559]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 15962, 18149, 19445, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [843, 5854, 8570, 15244, 18125]\nAdjustment completed; event ends [857, 5939, 8579, 15269, 18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18135]\nAdjustment completed; event ends [18149]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [18138]\nAdjustment completed; event ends [18149]\nF_score funct. [[0.10143824 1.         0.18419233]\n [0.09836972 0.44537114 0.16114674]\n [1.         0.38657214 0.55759398]\n [1.         0.02543786 0.04961366]\n [1.         0.01251043 0.0247117 ]\n [1.         0.01292744 0.02552491]]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3719, 5853, 7143, 8569, 12370, 13800, 15243, 18119, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3720, 5853, 7143, 8570, 12370, 13800, 15243, 18119, 19560]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [839, 3720, 5853, 7143, 8570, 12371, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 12373, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 13800, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 13824, 15269, 18149, 19589]\nEvaluation: Adjusting predictions ...\nAdjustment completed; event starts [840, 3720, 5854, 7143, 8570, 15243, 18120, 19563]\nAdjustment completed; event ends [857, 4173, 5939, 7999, 8579, 15269, 18149, 19589]\nModel 2 is model\nScores before AD event aggregation\nPrec= 0.10655408122235625 Rec= 0.9945788156797332 F1= 0.19248617892740405\n========================================================================= \n\nScores after AD event aggregation and k-sigma = [2,3,4,5,6,7,8] thresholding\nPrec= [0.99379524 0.99791449 0.99895507 1.         1.         1.        ]\nRec= [0.40075063 0.39908257 0.39866555 0.38615513 0.38115096 0.37614679]\nF1= [0.57117385 0.57015192 0.56989568 0.55716005 0.55193237 0.54666667]\nModel 2 is model\n32/32 [==============================] - 0s 10ms/step\n(1024, 120, 38)\n(9, 120, 38)\n(1080, 38)\ntf.Tensor(\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], shape=(623, 38), dtype=float64)\nModel 2 is model\nModel 2 is model\n7/7 [==============================] - 0s 9ms/step\n(197, 120, 38)\n(2, 120, 38)\n(240, 38)\nModel 2 is model\ntf.Tensor(\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], shape=(608, 38), dtype=float64)\nModel 2 is model\nModel 2 is model\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:38:29.724467Z",
          "iopub.status.idle": "2024-02-23T12:38:29.724855Z",
          "shell.execute_reply.started": "2024-02-23T12:38:29.724670Z",
          "shell.execute_reply": "2024-02-23T12:38:29.724689Z"
        },
        "trusted": true,
        "id": "VAN64l6hwZSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all (perf. only, since training history was saved during training) metrics into a .CSV file\n",
        "# import pandas as pd\n",
        "# import os\n",
        "# import pickle\n",
        "\n",
        "# # Main loop#1: All or selected subsets of the 28 machine names from the SMD dataset\n",
        "# machine_names = [\"machine-2-4\", \"machine-2-5\", \"machine-2-6\", \"machine-2-7\", \"machine-2-8\", \"machine-2-9\", \"machine-3-1\", \"machine-3-2\", \"machine-3-3\", \"machine-3-4\", \"machine-3-5\", \"machine-3-6\", \"machine-3-7\", \"machine-3-8\", \"machine-3-9\", \"machine-3-10\", \"machine-3-11\"]\n",
        "# # List of the 4 AE model names\n",
        "# model_names = [\"snu-ae\", \"snu-transformer\", \"lstm\", \"transformer\"]\n",
        "\n",
        "# # Define a dictionary for model indices\n",
        "# model_indices = {\n",
        "#     \"snu-ae\": 1,\n",
        "#     \"snu-transformer\": 2,\n",
        "#     \"lstm\": 3,\n",
        "#     \"transformer\": 4\n",
        "# }\n",
        "\n",
        "# Initialize a list to store the models again, iff we build and append all the models anew (rare need)\n",
        "# model_list = []\n",
        "\n",
        "# Initialize an empty list to store all performance metrics\n",
        "all_performance_metrics = []\n",
        "\n",
        "# Loop over each machine\n",
        "for i_mach, machine_name in enumerate(machine_names):\n",
        "    # Define the base directory\n",
        "    base_dir = os.path.join(results_dir, machine_name)\n",
        "\n",
        "    # Loop over each model\n",
        "    for model_name_str, model_index in model_indices.items():\n",
        "        # Check if the pickle file exists\n",
        "        pickle_filepath = os.path.join(base_dir, f'{model_name_str}/performance_metrics_model_{model_index}.pkl')\n",
        "        exists = os.path.isfile(pickle_filepath)\n",
        "\n",
        "        # If the file exists, load the performance metrics\n",
        "        if exists:\n",
        "            with open(pickle_filepath, 'rb') as f:\n",
        "                performance_metrics = pickle.load(f)\n",
        "\n",
        "            # Add the machine name and model name to the performance metrics\n",
        "            performance_metrics['machine_name'] = machine_name\n",
        "            performance_metrics['model_name'] = model_name_str\n",
        "\n",
        "            # Add the performance metrics to the list\n",
        "            all_performance_metrics.append(performance_metrics)\n",
        "        else:\n",
        "            # If the file doesn't exist, set the performance metrics to -1\n",
        "            performance_metrics = {'machine_name': machine_name, 'model_name': model_name_str, 'avg_score': -1}\n",
        "            all_performance_metrics.append(performance_metrics)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(all_performance_metrics)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(os.path.join(results_dir, 'performance_metrics.csv'), index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:38:29.726567Z",
          "iopub.status.idle": "2024-02-23T12:38:29.727042Z",
          "shell.execute_reply.started": "2024-02-23T12:38:29.726795Z",
          "shell.execute_reply": "2024-02-23T12:38:29.726826Z"
        },
        "trusted": true,
        "id": "B3WHNADPwZSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save only the max F1 values (incl. its Prec and Recall)\n",
        "\n",
        "# Initialize an empty list to store all performance metrics\n",
        "all_performance_metrics = []\n",
        "\n",
        "# Loop over each machine\n",
        "for i_mach, machine_name in enumerate(machine_names):\n",
        "    # Define the base directory\n",
        "    base_dir = os.path.join(results_dir, machine_name)\n",
        "\n",
        "    # Loop over each model\n",
        "    for model_name_str, model_index in model_indices.items():\n",
        "        # Check if the pickle file exists\n",
        "        pickle_filepath = os.path.join(base_dir, f'{model_name_str}/performance_metrics_model_{model_index}.pkl')\n",
        "        exists = os.path.isfile(pickle_filepath)\n",
        "\n",
        "        # If the file exists, load the performance metrics\n",
        "        if exists:\n",
        "            with open(pickle_filepath, 'rb') as f:\n",
        "                performance_metrics = pickle.load(f)\n",
        "\n",
        "            # Find the index of the maximum F1 score\n",
        "            max_f1_index = np.argmax(performance_metrics['f1'])\n",
        "\n",
        "            # Use this index to find the corresponding precision and recall\n",
        "            p_max = performance_metrics['p'][max_f1_index]\n",
        "            r_max = performance_metrics['r'][max_f1_index]\n",
        "            f1_max = performance_metrics['f1'][max_f1_index]\n",
        "\n",
        "            # For global CSV: Add the machine name, model name, and maximum scores to the performance metrics\n",
        "            performance_metrics_max = {\n",
        "                'machine_name': machine_name,\n",
        "                'model_name': model_name_str,\n",
        "                'p_max': p_max,\n",
        "                'r_max': r_max,\n",
        "                'f1_max': f1_max,\n",
        "                'max_f1_index': max_f1_index\n",
        "            }\n",
        "\n",
        "            # Add the performance metrics to the list\n",
        "            all_performance_metrics.append(performance_metrics_max)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(all_performance_metrics)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(os.path.join(results_dir, 'performance_metrics_max.csv'), index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:38:29.728107Z",
          "iopub.status.idle": "2024-02-23T12:38:29.728596Z",
          "shell.execute_reply.started": "2024-02-23T12:38:29.728357Z",
          "shell.execute_reply": "2024-02-23T12:38:29.728379Z"
        },
        "trusted": true,
        "id": "hrC8eC-TwZSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the final (best) F1 scores of all 4 models across all 28 SMD machines\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# machine_names = [\"machine-1-1\", \"machine-1-2\", \"machine-1-3\", \"machine-1-4\", \"machine-1-5\", \"machine-1-6\", \"machine-1-7\", \"machine-1-8\", \"machine-2-1\", \"machine-2-2\", \"machine-2-3\"]#, \"machine-2-4\", \"machine-2-5\", \"machine-2-6\", \"machine-2-7\", \"machine-2-8\", \"machine-2-9\", \"machine-3-1\", \"machine-3-2\", \"machine-3-3\", \"machine-3-4\", \"machine-3-5\", \"machine-3-6\", \"machine-3-7\", \"machine-3-8\", \"machine-3-9\", \"machine-3-10\", \"machine-3-11\"]\n",
        "# # List of the 4 AE model names\n",
        "# model_names = [\"snu-ae\", \"snu-transformer\", \"lstm\", \"transformer\"]\n",
        "\n",
        "#results_dir = 'C:\\\\Downloads\\\\smd\\\\res1\\\\kaggle\\\\working\\\\results\\\\'\n",
        "\n",
        "# Define the model colors\n",
        "model_colors = {\n",
        "    'snu-ae': 'cyan',\n",
        "    'snu-transformer': 'blue',\n",
        "    'lstm': 'red',\n",
        "    'transformer': 'black'\n",
        "}\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(os.path.join(results_dir, 'performance_metrics_max.csv'))\n",
        "\n",
        "# Loop over each model\n",
        "for model_name in model_names:\n",
        "    # Filter the DataFrame for the current model\n",
        "    df_model = df[df['model_name'] == model_name]\n",
        "\n",
        "    # Plot the maximum F1 score for the current model\n",
        "    plt.plot(df_model['machine_name'], df_model['f1_max'], color=model_colors[model_name], label=model_name)\n",
        "\n",
        "\n",
        "    # Add annotations for the max F1 indices (K-sigma cut-off thresholds,for our AD a value within 2-8 std. deviations)\n",
        "    for i, max_f1_index in enumerate(df_model['max_f1_index']):\n",
        "        plt.annotate(str(max_f1_index+1), (df_model['machine_name'].iloc[i], df_model['f1_max'].iloc[i]))\n",
        "\n",
        "\n",
        "# Add labels and a legend to the plot\n",
        "plt.xlabel('Machine')\n",
        "plt.ylabel('Max F1 Score')\n",
        "plt.title('Max F1 Score for Each Model Across All Machines')\n",
        "plt.legend()\n",
        "\n",
        "# # Display the plot\n",
        "# plt.show()\n",
        "\n",
        "plt.savefig(os.path.join(results_dir, f'F1_all_models.png'))\n",
        "plt.close()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:38:29.730182Z",
          "iopub.status.idle": "2024-02-23T12:38:29.730563Z",
          "shell.execute_reply.started": "2024-02-23T12:38:29.730396Z",
          "shell.execute_reply": "2024-02-23T12:38:29.730413Z"
        },
        "trusted": true,
        "id": "qAJimJYIwZSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Working dirs at FINALE =>\", results_dir, \"base_dir=\", base_dir, \"machine_name=\", machine_name, \"model_name_str=\", model_name_str, \"machine_model_dir=\", machine_model_dir)\n",
        "# !zip -r smd_res2.zip /kaggle/working/results2/\n",
        "# !rm -r /kaggle/working/results2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-23T12:38:29.732872Z",
          "iopub.status.idle": "2024-02-23T12:38:29.733360Z",
          "shell.execute_reply.started": "2024-02-23T12:38:29.733110Z",
          "shell.execute_reply": "2024-02-23T12:38:29.733129Z"
        },
        "trusted": true,
        "id": "0yU-ABgFwZSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "0rpvWytywZSJ"
      }
    }
  ]
}